{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# 02 Feature Engineering - Extract telemetry features\n",
    "\n",
    "Goal: Build a pipeline that turns raw lap data into features I can feed into the Bayesian model.\n",
    "\n",
    "Pipeline flow:\n",
    "1. Single lap â†’ extract telemetry features (speed, throttle, braking, etc.)\n",
    "2. Driver session â†’ aggregate all their laps\n",
    "3. Full session â†’ calculate relative performance (who's fastest?)\n",
    "4. Export â†’ ready for predictions\n",
    "\n",
    "This will move to `src/` later as production code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineering Pipeline\n"
     ]
    }
   ],
   "source": [
    "import fastf1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"fastf1\").setLevel(logging.ERROR)\n",
    "\n",
    "cache_dir = Path('../data/raw/.fastf1_cache')\n",
    "fastf1.Cache.enable_cache(str(cache_dir))\n",
    "\n",
    "print(\"Feature Engineering Pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1",
   "metadata": {},
   "source": [
    "## Part 1: Single lap features\n",
    "\n",
    "Core building block - extract features from one lap of telemetry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lap_extractor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: Extract features from Verstappen's lap in 2024 testing\n",
      "Lap 12.0: 0 days 00:01:33.991000\n",
      "\n",
      "Extracted 13 features:\n",
      "  slow_corner_speed: 91.3\n",
      "  medium_corner_speed: 147.0\n",
      "  high_corner_speed: 225.4\n",
      "  pct_full_throttle: 57.4\n",
      "  avg_throttle: 69.7\n",
      "\n",
      "ðŸŸ¢ Single lap extraction works\n"
     ]
    }
   ],
   "source": [
    "class LapFeatureExtractor:\n",
    "    \"\"\"Extract telemetry features from a single F1 lap.\"\"\"\n",
    "    \n",
    "    def __init__(self, corner_speed_thresholds=None):\n",
    "        \"\"\"\n",
    "        Corner speed thresholds for classification.\n",
    "        Default: slow <100, medium 100-200, high 200-250 km/h\n",
    "        \"\"\"\n",
    "        if corner_speed_thresholds is None:\n",
    "            self.corner_thresholds = {\n",
    "                'slow': (0, 100),\n",
    "                'medium': (100, 200),\n",
    "                'high': (200, 250)\n",
    "            }\n",
    "        else:\n",
    "            self.corner_thresholds = corner_speed_thresholds\n",
    "    \n",
    "    def extract_corner_speeds(self, telemetry):\n",
    "        \"\"\"Average speed in slow/medium/high-speed corners.\"\"\"\n",
    "        # Corners are anywhere under 250 km/h (arbitrary but works)\n",
    "        corners = telemetry[telemetry['Speed'] < 250]\n",
    "        \n",
    "        speeds = {}\n",
    "        for corner_type, (min_speed, max_speed) in self.corner_thresholds.items():\n",
    "            mask = (corners['Speed'] >= min_speed) & (corners['Speed'] < max_speed)\n",
    "            corner_data = corners[mask]\n",
    "            \n",
    "            if len(corner_data) > 0:\n",
    "                speeds[f'{corner_type}_corner_speed'] = corner_data['Speed'].mean()\n",
    "            else:\n",
    "                speeds[f'{corner_type}_corner_speed'] = np.nan\n",
    "        \n",
    "        return speeds\n",
    "    \n",
    "    def extract_throttle_metrics(self, telemetry):\n",
    "        \"\"\"Throttle usage - percentage at full throttle, average, smoothness.\"\"\"\n",
    "        throttle = telemetry['Throttle']\n",
    "        \n",
    "        return {\n",
    "            'pct_full_throttle': (throttle == 100).sum() / len(throttle) * 100,\n",
    "            'avg_throttle': throttle.mean(),\n",
    "            'throttle_smoothness': throttle.std()  # lower = smoother\n",
    "        }\n",
    "    \n",
    "    def extract_braking_metrics(self, telemetry):\n",
    "        \"\"\"Braking zones and intensity.\"\"\"\n",
    "        brake = telemetry['Brake']\n",
    "        \n",
    "        # Count braking zones (transitions from 0 to >0)\n",
    "        braking_points = ((brake > 0) & (brake.shift(1) == 0)).sum()\n",
    "        \n",
    "        return {\n",
    "            'braking_pct': (brake > 0).sum() / len(brake) * 100,\n",
    "            'braking_zones': braking_points,\n",
    "            'avg_brake_intensity': brake[brake > 0].mean() if (brake > 0).any() else 0\n",
    "        }\n",
    "    \n",
    "    def extract_straight_line_speed(self, telemetry):\n",
    "        \"\"\"Top speed and speed at full throttle.\"\"\"\n",
    "        full_throttle = telemetry[telemetry['Throttle'] == 100]\n",
    "        \n",
    "        # Max gear (usually 8th) indicates straight-line running\n",
    "        max_gear = telemetry['nGear'].max()\n",
    "        top_gear = telemetry[telemetry['nGear'] == max_gear]\n",
    "        \n",
    "        return {\n",
    "            'avg_speed_full_throttle': full_throttle['Speed'].mean() if len(full_throttle) > 0 else np.nan,\n",
    "            'max_speed': telemetry['Speed'].max(),\n",
    "            'pct_at_max_gear': len(top_gear) / len(telemetry) * 100\n",
    "        }\n",
    "    \n",
    "    def extract_drs_usage(self, telemetry):\n",
    "        \"\"\"How much DRS was available and used.\"\"\"\n",
    "        drs = telemetry['DRS']\n",
    "        return {'drs_active_pct': (drs > 0).sum() / len(drs) * 100}\n",
    "    \n",
    "    def extract_features(self, lap) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Extract all features from a lap.\n",
    "        Returns dict of feature_name -> value.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            telemetry = lap.get_telemetry()\n",
    "            \n",
    "            if telemetry is None or len(telemetry) == 0:\n",
    "                return {}\n",
    "            \n",
    "            # Combine all feature extractors\n",
    "            features = {}\n",
    "            features.update(self.extract_corner_speeds(telemetry))\n",
    "            features.update(self.extract_throttle_metrics(telemetry))\n",
    "            features.update(self.extract_braking_metrics(telemetry))\n",
    "            features.update(self.extract_straight_line_speed(telemetry))\n",
    "            features.update(self.extract_drs_usage(telemetry))\n",
    "            \n",
    "            return features\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Sometimes telemetry fails to load\n",
    "            return {}\n",
    "\n",
    "\n",
    "# Quick test on a real lap\n",
    "print(\"\\nTest: Extract features from Verstappen's lap in 2024 testing\")\n",
    "\n",
    "session = fastf1.get_session(2024, 'Testing', 1)\n",
    "session.load()\n",
    "\n",
    "ver_laps = session.laps.pick_drivers('VER')\n",
    "lap = ver_laps.iloc[len(ver_laps) // 2] if len(ver_laps) > 0 else ver_laps.iloc[0]\n",
    "\n",
    "extractor = LapFeatureExtractor()\n",
    "features = extractor.extract_features(lap)\n",
    "\n",
    "print(f\"Lap {lap['LapNumber']}: {lap['LapTime']}\")\n",
    "print(f\"\\nExtracted {len(features)} features:\")\n",
    "for k, v in list(features.items())[:5]:\n",
    "    print(f\"  {k}: {v:.1f}\")\n",
    "\n",
    "print(\"\\nðŸŸ¢ Single lap extraction works\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2",
   "metadata": {},
   "source": [
    "## Part 2: Aggregate driver session\n",
    "\n",
    "One driver does ~60 laps in a session. I need to aggregate them into representative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "session_aggregator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: Extract features for all drivers in FP1\n",
      "\n",
      "Extracted features for 20 drivers\n",
      "Features per driver: 32\n",
      "\n",
      "Fastest 3:\n",
      "   driver_code             team  fastest_lap  clean_laps\n",
      "16         SAI          Ferrari       93.602          14\n",
      "5          LEC          Ferrari       93.623          16\n",
      "0          VER  Red Bull Racing       93.855          11\n",
      "\n",
      "ðŸŸ¢ Session aggregation works\n"
     ]
    }
   ],
   "source": [
    "class SessionFeatureAggregator:\n",
    "    \"\"\"Aggregate lap-level features into session-level features for a driver.\"\"\"\n",
    "    \n",
    "    def __init__(self, lap_extractor):\n",
    "        self.lap_extractor = lap_extractor\n",
    "    \n",
    "    def filter_clean_laps(self, laps):\n",
    "        \"\"\"\n",
    "        Remove outliers and invalid laps.\n",
    "        Keep laps where: in-lap, out-lap, yellow flags, accidents filtered out.\n",
    "        \"\"\"\n",
    "        # Basic filters\n",
    "        clean = laps[\n",
    "            (laps['IsAccurate'] == True) &\n",
    "            (laps['TrackStatus'] == '1')  # Green flag\n",
    "        ].copy()\n",
    "        \n",
    "        # Remove statistical outliers (more than 3 std from median)\n",
    "        if len(clean) > 5:\n",
    "            lap_times = clean['LapTime'].dt.total_seconds()\n",
    "            median = lap_times.median()\n",
    "            std = lap_times.std()\n",
    "            \n",
    "            clean = clean[abs(lap_times - median) < 3 * std]\n",
    "        \n",
    "        return clean\n",
    "    \n",
    "    def extract_driver_session(self, laps) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Extract features for one driver's session.\n",
    "        Returns aggregated features (median across clean laps).\n",
    "        \"\"\"\n",
    "        if len(laps) == 0:\n",
    "            return {}\n",
    "        \n",
    "        # Basic info\n",
    "        driver_info = {\n",
    "            'driver_number': str(laps.iloc[0]['DriverNumber']),\n",
    "            'driver_code': laps.iloc[0]['Driver'],\n",
    "            'team': laps.iloc[0]['Team'],\n",
    "            'total_laps': len(laps)\n",
    "        }\n",
    "        \n",
    "        # Filter to clean laps only\n",
    "        clean_laps = self.filter_clean_laps(laps)\n",
    "        driver_info['clean_laps'] = len(clean_laps)\n",
    "        \n",
    "        if len(clean_laps) == 0:\n",
    "            return driver_info\n",
    "        \n",
    "        # Fastest lap (key metric for practice sessions)\n",
    "        fastest = clean_laps.pick_fastest()\n",
    "        driver_info['fastest_lap'] = fastest['LapTime'].total_seconds()\n",
    "        \n",
    "        # Extract features from all clean laps\n",
    "        lap_features = []\n",
    "        for idx, lap in clean_laps.iterrows():\n",
    "            features = self.lap_extractor.extract_features(lap)\n",
    "            if features:  # Skip if telemetry failed\n",
    "                lap_features.append(features)\n",
    "        \n",
    "        if len(lap_features) == 0:\n",
    "            return driver_info\n",
    "        \n",
    "        # Aggregate: median across all laps (robust to outliers)\n",
    "        df = pd.DataFrame(lap_features)\n",
    "        aggregated = df.median().to_dict()\n",
    "        \n",
    "        # Also track consistency (std)\n",
    "        for col in df.columns:\n",
    "            aggregated[f'{col}_std'] = df[col].std()\n",
    "        \n",
    "        # Merge with driver info\n",
    "        return {**driver_info, **aggregated}\n",
    "    \n",
    "    def extract_all_drivers(self, session) -> pd.DataFrame:\n",
    "        \"\"\"Extract features for all drivers in a session.\"\"\"\n",
    "        driver_features = []\n",
    "        \n",
    "        for driver in session.laps['Driver'].unique():\n",
    "            driver_laps = session.laps.pick_drivers(driver)\n",
    "            features = self.extract_driver_session(driver_laps)\n",
    "            \n",
    "            if features and 'fastest_lap' in features:\n",
    "                driver_features.append(features)\n",
    "        \n",
    "        return pd.DataFrame(driver_features)\n",
    "\n",
    "\n",
    "# Test on full session\n",
    "print(\"\\nTest: Extract features for all drivers in FP1\")\n",
    "\n",
    "aggregator = SessionFeatureAggregator(extractor)\n",
    "session_features = aggregator.extract_all_drivers(session)\n",
    "\n",
    "print(f\"\\nExtracted features for {len(session_features)} drivers\")\n",
    "print(f\"Features per driver: {len(session_features.columns)}\")\n",
    "print(f\"\\nFastest 3:\")\n",
    "print(session_features.nsmallest(3, 'fastest_lap')[['driver_code', 'team', 'fastest_lap', 'clean_laps']])\n",
    "\n",
    "print(\"\\nðŸŸ¢ Session aggregation works\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3",
   "metadata": {},
   "source": [
    "## Part 3: Relative performance\n",
    "\n",
    "Absolute lap times don't mean much (depends on track, conditions, etc.).\n",
    "I need relative performance - how fast is this driver compared to the field?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "relative_perf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: Calculate relative performance\n",
      "\n",
      "Added relative features:\n",
      "  29 relative columns\n",
      "\n",
      "Top 3 by fastest lap percentile:\n",
      "   driver_code  fastest_lap  fastest_lap_rel  fastest_lap_pct\n",
      "10         ZHO       97.219           2.8805            100.0\n",
      "14         COL       95.248           0.9095             95.0\n",
      "18         BOT       95.041           0.7025             90.0\n",
      "\n",
      "ðŸŸ¢ Relative performance works\n"
     ]
    }
   ],
   "source": [
    "class RelativePerformanceCalculator:\n",
    "    \"\"\"Convert absolute features to relative performance vs field.\"\"\"\n",
    "    \n",
    "    def __init__(self, use_median=True):\n",
    "        \"\"\"\n",
    "        use_median: If True, normalize to median (robust to outliers).\n",
    "                   If False, normalize to mean.\n",
    "        \"\"\"\n",
    "        self.use_median = use_median\n",
    "    \n",
    "    def normalize_features(self, features_df):\n",
    "        \"\"\"\n",
    "        Add relative features: difference from field median/mean.\n",
    "        Prefix: 'fastest_lap_rel', 'avg_throttle_rel', etc.\n",
    "        \"\"\"\n",
    "        df = features_df.copy()\n",
    "        \n",
    "        # Identify numeric columns (skip metadata like driver_code)\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        \n",
    "        for col in numeric_cols:\n",
    "            if df[col].notna().sum() < 2:\n",
    "                continue  # Skip if not enough data\n",
    "            \n",
    "            if self.use_median:\n",
    "                baseline = df[col].median()\n",
    "            else:\n",
    "                baseline = df[col].mean()\n",
    "            \n",
    "            df[f'{col}_rel'] = df[col] - baseline\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def add_percentile_ranks(self, features_df):\n",
    "        \"\"\"\n",
    "        Add percentile ranks for key features.\n",
    "        Example: fastest_lap_pct = 95 means faster than 95% of field.\n",
    "        \"\"\"\n",
    "        df = features_df.copy()\n",
    "        \n",
    "        # Lower is better for lap times\n",
    "        if 'fastest_lap' in df.columns:\n",
    "            df['fastest_lap_pct'] = df['fastest_lap'].rank(pct=True, ascending=True) * 100\n",
    "        \n",
    "        # Higher is better for speed metrics\n",
    "        speed_cols = [col for col in df.columns if 'speed' in col.lower() and '_rel' not in col]\n",
    "        for col in speed_cols:\n",
    "            if col in df.columns:\n",
    "                df[f'{col}_pct'] = df[col].rank(pct=True, ascending=False) * 100\n",
    "        \n",
    "        return df\n",
    "\n",
    "\n",
    "# Test relative performance\n",
    "print(\"\\nTest: Calculate relative performance\")\n",
    "\n",
    "rel_calc = RelativePerformanceCalculator(use_median=True)\n",
    "normalized = rel_calc.normalize_features(session_features)\n",
    "with_ranks = rel_calc.add_percentile_ranks(normalized)\n",
    "\n",
    "print(f\"\\nAdded relative features:\")\n",
    "rel_cols = [col for col in with_ranks.columns if '_rel' in col]\n",
    "print(f\"  {len(rel_cols)} relative columns\")\n",
    "\n",
    "print(f\"\\nTop 3 by fastest lap percentile:\")\n",
    "print(with_ranks.nlargest(3, 'fastest_lap_pct')[['driver_code', 'fastest_lap', 'fastest_lap_rel', 'fastest_lap_pct']])\n",
    "\n",
    "print(\"\\nðŸŸ¢ Relative performance works\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4",
   "metadata": {},
   "source": [
    "## Part 4: Production pipeline\n",
    "\n",
    "Put it all together in one clean pipeline class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pipeline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: Process all 2024 testing sessions\n",
      "Processing 1/3: United States Grand Prix - Practice 1\n",
      "Processing 2/3: United States Grand Prix - Sprint Qualifying\n",
      "Processing 3/3: United States Grand Prix - Sprint\n",
      "\n",
      "ðŸŸ¢ Processed 3 sessions\n",
      "  60 total rows, 20 drivers\n",
      "\n",
      "Dataset shape: (60, 76)\n",
      "Feature completeness: 100.0%\n",
      "\n",
      "ðŸŸ¢ Production pipeline works\n"
     ]
    }
   ],
   "source": [
    "class F1FeaturePipeline:\n",
    "    \"\"\"\n",
    "    Complete feature extraction pipeline.\n",
    "    \n",
    "    Usage:\n",
    "        pipeline = F1FeaturePipeline()\n",
    "        features = pipeline.process_session(session)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.lap_extractor = LapFeatureExtractor()\n",
    "        self.session_aggregator = SessionFeatureAggregator(self.lap_extractor)\n",
    "        self.rel_calculator = RelativePerformanceCalculator(use_median=True)\n",
    "    \n",
    "    def process_session(self, session, add_metadata=True):\n",
    "        \"\"\"\n",
    "        Complete pipeline: Session â†’ Features with relative performance.\n",
    "        \n",
    "        Returns DataFrame with one row per driver.\n",
    "        \"\"\"\n",
    "        # Step 1: Extract raw features\n",
    "        features = self.session_aggregator.extract_all_drivers(session)\n",
    "        \n",
    "        if len(features) == 0:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Step 2: Calculate relative performance\n",
    "        normalized = self.rel_calculator.normalize_features(features)\n",
    "        with_ranks = self.rel_calculator.add_percentile_ranks(normalized)\n",
    "        \n",
    "        # Step 3: Add metadata\n",
    "        if add_metadata:\n",
    "            with_ranks['year'] = session.event['EventDate'].year\n",
    "            with_ranks['event'] = session.event['EventName']\n",
    "            with_ranks['session_type'] = session.name\n",
    "            with_ranks['session_date'] = session.date\n",
    "        \n",
    "        return with_ranks\n",
    "    \n",
    "    def process_multiple_sessions(self, sessions, verbose=True):\n",
    "        \"\"\"Process multiple sessions and combine.\"\"\"\n",
    "        all_features = []\n",
    "        \n",
    "        for i, session in enumerate(sessions):\n",
    "            if verbose:\n",
    "                print(f\"Processing {i+1}/{len(sessions)}: {session.event['EventName']} - {session.name}\")\n",
    "            \n",
    "            features = self.process_session(session)\n",
    "            if len(features) > 0:\n",
    "                all_features.append(features)\n",
    "        \n",
    "        if len(all_features) == 0:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        combined = pd.concat(all_features, ignore_index=True)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nðŸŸ¢ Processed {len(all_features)} sessions\")\n",
    "            print(f\"  {len(combined)} total rows, {combined['driver_number'].nunique()} drivers\")\n",
    "        \n",
    "        return combined\n",
    "\n",
    "\n",
    "# Test on 2024 testing (3 days)\n",
    "print(\"\\nTest: Process all 2024 testing sessions\")\n",
    "\n",
    "pipeline = F1FeaturePipeline()\n",
    "\n",
    "testing_sessions = []\n",
    "for day in range(1, 4):\n",
    "    s = fastf1.get_session(2024, 'Testing', day)\n",
    "    s.load()\n",
    "    testing_sessions.append(s)\n",
    "\n",
    "all_features = pipeline.process_multiple_sessions(testing_sessions)\n",
    "\n",
    "print(f\"\\nDataset shape: {all_features.shape}\")\n",
    "print(f\"Feature completeness: {all_features.notna().mean().mean() * 100:.1f}%\")\n",
    "\n",
    "print(\"\\nðŸŸ¢ Production pipeline works\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export",
   "metadata": {},
   "source": [
    "## Export features\n",
    "\n",
    "Save to parquet for fast loading in Bayesian validation notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "export_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŸ¢ Saved to ../data/processed/testing_files/2024_testing_features.parquet\n",
      "  Shape: (60, 76)\n",
      "  Size: 73.6 KB\n"
     ]
    }
   ],
   "source": [
    "output_dir = Path('../data/processed/testing_files')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output_file = output_dir / '2024_testing_features.parquet'\n",
    "all_features.to_parquet(output_file, index=False)\n",
    "\n",
    "print(f\"ðŸŸ¢ Saved to {output_file}\")\n",
    "print(f\"  Shape: {all_features.shape}\")\n",
    "print(f\"  Size: {output_file.stat().st_size / 1024:.1f} KB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
