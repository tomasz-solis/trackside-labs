{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver Position Validation\n",
    "\n",
    "Validates driver position predictions (1-20) against actual F1 results.\n",
    "\n",
    "**Tests:**\n",
    "- Overall MAE and bias\n",
    "- Position accuracy (¬±1, ¬±2, ¬±3)\n",
    "- Confidence interval coverage\n",
    "- Performance by experience tier\n",
    "\n",
    "**Fixes:** -11 position bias by predicting driver positions instead of team ranks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffd09376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastf1 as ff1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "sys.path.append('../')\n",
    "from src.predictors.driver_predictor import DriverRanker\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"fastf1\").setLevel(logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "ff1.Cache.enable_cache('../data/raw/.fastf1_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dd61c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating driver_characteristics.json...\n",
      "======================================================================\n",
      "Found 27 drivers\n",
      "‚úÖ Created ../data/processed/testing_files/driver_characteristics/driver_characteristics.json\n",
      "‚úÖ 27 drivers ready\n"
     ]
    }
   ],
   "source": [
    "# CREATE driver_characteristics.json\n",
    "\n",
    "print(\"Creating driver_characteristics.json...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "base_path = Path('../data/processed/testing_files/driver_characteristics')\n",
    "\n",
    "# Load ratio files\n",
    "with open(base_path / 'driver_quali_characteristics.json') as f:\n",
    "    quali_ratios = json.load(f)\n",
    "\n",
    "with open(base_path / 'driver_race_characteristics.json') as f:\n",
    "    race_ratios = json.load(f)\n",
    "\n",
    "# Get all unique drivers\n",
    "all_drivers = set()\n",
    "for comp in quali_ratios:\n",
    "    all_drivers.add(comp['driver'])\n",
    "for comp in race_ratios:\n",
    "    all_drivers.add(comp['driver'])\n",
    "\n",
    "print(f\"Found {len(all_drivers)} drivers\")\n",
    "\n",
    "# Aggregate ratios per driver\n",
    "quali_by_driver = defaultdict(list)\n",
    "race_by_driver = defaultdict(list)\n",
    "\n",
    "for comp in quali_ratios:\n",
    "    quali_by_driver[comp['driver']].append(comp['ratio'])\n",
    "\n",
    "for comp in race_ratios:\n",
    "    race_by_driver[comp['driver']].append(comp['ratio'])\n",
    "\n",
    "# Simple tier assignment based on ratio\n",
    "def assign_tier(driver, avg_ratio):\n",
    "    \"\"\"Simple tier based on pace.\"\"\"\n",
    "    # ratio < 0.995 = very fast (veteran/established)\n",
    "    # ratio 0.995-1.005 = average (developing)\n",
    "    # ratio > 1.005 = slower (rookie)\n",
    "    \n",
    "    if avg_ratio < 0.995:\n",
    "        return 'veteran'\n",
    "    elif avg_ratio < 1.005:\n",
    "        return 'established'\n",
    "    else:\n",
    "        return 'developing'\n",
    "\n",
    "# Create structure\n",
    "unified = {\n",
    "    'year': 2024,\n",
    "    'total_drivers': len(all_drivers),\n",
    "    'drivers': {}\n",
    "}\n",
    "\n",
    "for driver in sorted(all_drivers):\n",
    "    # Average ratios\n",
    "    quali_ratio = np.mean(quali_by_driver[driver]) if driver in quali_by_driver else 1.0\n",
    "    race_ratio = np.mean(race_by_driver[driver]) if driver in race_by_driver else 1.0\n",
    "    \n",
    "    # Assign tier\n",
    "    tier = assign_tier(driver, quali_ratio)\n",
    "    \n",
    "    # Convert ratio to pace (ratio < 1.0 = faster)\n",
    "    quali_pace = 0.5 + (1.0 - quali_ratio) * 5\n",
    "    quali_pace = max(0.3, min(0.7, quali_pace))\n",
    "    \n",
    "    unified['drivers'][driver] = {\n",
    "        'experience': {\n",
    "            'tier': tier,\n",
    "            'total_seasons': 5  # Default\n",
    "        },\n",
    "        'pace': {\n",
    "            'quali_pace': float(quali_pace)\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Save\n",
    "output_path = base_path / 'driver_characteristics.json'\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(unified, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Created {output_path}\")\n",
    "print(f\"‚úÖ {len(unified['drivers'])} drivers ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a1c4a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded characteristics for 27 drivers\n",
      "üü¢ Loaded 27 driver profiles\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Load driver ranker\n",
    "    driver_ranker = DriverRanker(\n",
    "        '../data/processed/testing_files/driver_characteristics/driver_characteristics.json'\n",
    "    )\n",
    "\n",
    "    # Load enriched data for tier analysis\n",
    "    with open('../data/processed/testing_files/driver_characteristics/driver_characteristics.json') as f:\n",
    "        enriched_data = json.load(f)\n",
    "\n",
    "    print(f\"üü¢ Loaded {enriched_data['total_drivers']} driver profiles\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"üî¥ Failed to load driver ranker: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc339e19",
   "metadata": {},
   "source": [
    "## Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89fab524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üü¢ Validation function ready\n"
     ]
    }
   ],
   "source": [
    "def validate_session(year, event, session_type_char):\n",
    "    \"\"\"\n",
    "    Validate driver position predictions for one session.\n",
    "    \n",
    "    Uses actual team average positions to create team predictions,\n",
    "    then converts to driver positions and compares to actual results.\n",
    "    \"\"\"\n",
    "    session_name = 'qualifying' if session_type_char == 'Q' else 'race'\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"[{year}] {event} - {session_name.upper()}\")\n",
    "    print('='*70)\n",
    "    \n",
    "    # Load session\n",
    "    try:\n",
    "        session = ff1.get_session(year, event, session_type_char)\n",
    "        session.load(laps=False, telemetry=False, weather=False)\n",
    "    except Exception as e:\n",
    "        print(f\"üî¥ Failed: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Extract actual positions\n",
    "    actual_positions = {}\n",
    "    for _, driver in session.results.iterrows():\n",
    "        abbr = driver['Abbreviation']\n",
    "        pos = driver['Position']\n",
    "        if pd.notna(pos) and pd.notna(abbr):\n",
    "            actual_positions[abbr] = int(pos)\n",
    "    \n",
    "    if not actual_positions:\n",
    "        return None\n",
    "    \n",
    "    # Extract team lineups\n",
    "    lineups = {}\n",
    "    for team_name in session.results['TeamName'].unique():\n",
    "        drivers = session.results[session.results['TeamName'] == team_name]['Abbreviation'].tolist()\n",
    "        if len(drivers) >= 2:\n",
    "            lineups[team_name] = drivers[:2]\n",
    "    \n",
    "    # Create team predictions based on actual average positions\n",
    "    # NOTE: In production, replace with Bayesian model predictions\n",
    "    team_avg_pos = {\n",
    "        team: np.mean([actual_positions.get(d, 20) for d in drvs])\n",
    "        for team, drvs in lineups.items()\n",
    "    }\n",
    "    \n",
    "    team_predictions = {\n",
    "        team: rank + 1\n",
    "        for rank, (team, _) in enumerate(sorted(team_avg_pos.items(), key=lambda x: x[1]))\n",
    "    }\n",
    "    \n",
    "    # Predict driver positions\n",
    "    try:\n",
    "        results = driver_ranker.predict_positions(\n",
    "            team_predictions=team_predictions,\n",
    "            team_lineups=lineups,\n",
    "            session_type=session_name\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"üî¥ Prediction failed: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Compare predictions vs actuals\n",
    "    comparisons = []\n",
    "    for pred in results['predictions']:\n",
    "        if pred.driver not in actual_positions:\n",
    "            continue\n",
    "        \n",
    "        actual = actual_positions[pred.driver]\n",
    "        error = pred.position - actual\n",
    "        tier = enriched_data['drivers'].get(pred.driver, {}).get('experience', {}).get('tier', 'unknown')\n",
    "        \n",
    "        comparisons.append({\n",
    "            'driver': pred.driver,\n",
    "            'predicted': pred.position,\n",
    "            'actual': actual,\n",
    "            'error': error,\n",
    "            'abs_error': abs(error),\n",
    "            'tier': tier,\n",
    "            'in_ci': pred.confidence_lower <= actual <= pred.confidence_upper\n",
    "        })\n",
    "    \n",
    "    if not comparisons:\n",
    "        return None\n",
    "    \n",
    "    df = pd.DataFrame(comparisons)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'year': year,\n",
    "        'event': event,\n",
    "        'session': session_name,\n",
    "        'n_drivers': len(comparisons),\n",
    "        'mae': df['abs_error'].mean(),\n",
    "        'bias': df['error'].mean(),\n",
    "        'rmse': np.sqrt((df['error'] ** 2).mean()),\n",
    "        'accuracy_1': (df['abs_error'] <= 1).mean(),\n",
    "        'accuracy_2': (df['abs_error'] <= 2).mean(),\n",
    "        'accuracy_3': (df['abs_error'] <= 3).mean(),\n",
    "        'ci_coverage': df['in_ci'].mean(),\n",
    "        'comparisons': comparisons\n",
    "    }\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"MAE: {metrics['mae']:.2f}  Bias: {metrics['bias']:+.2f}  \"\n",
    "          f\"¬±1: {metrics['accuracy_1']*100:.0f}%  CI: {metrics['ci_coverage']*100:.0f}%\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "print(\"üü¢ Validation function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e624b",
   "metadata": {},
   "source": [
    "## Test Sessions\n",
    "\n",
    "Validates on 2024-2025 qualifying and race sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a6600d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test sessions\n",
    "test_sessions = [\n",
    "    # 2024 Qualifying\n",
    "    (2024, 'Bahrain Grand Prix', 'Q'),\n",
    "    (2024, 'Saudi Arabian Grand Prix', 'Q'),\n",
    "    (2024, 'Australian Grand Prix', 'Q'),\n",
    "    (2024, 'Japanese Grand Prix', 'Q'),\n",
    "    (2024, 'Chinese Grand Prix', 'Q'),\n",
    "    (2024, 'Miami Grand Prix', 'Q'),\n",
    "    (2024, 'Emilia Romagna Grand Prix', 'Q'),\n",
    "    (2024, 'Monaco Grand Prix', 'Q'),\n",
    "    (2024, 'Canadian Grand Prix', 'Q'),\n",
    "    (2024, 'Spanish Grand Prix', 'Q'),\n",
    "    \n",
    "    # 2024 Races\n",
    "    (2024, 'Bahrain Grand Prix', 'R'),\n",
    "    (2024, 'Saudi Arabian Grand Prix', 'R'),\n",
    "    (2024, 'Australian Grand Prix', 'R'),\n",
    "    \n",
    "    # 2025 Qualifying\n",
    "    (2025, 'Bahrain Grand Prix', 'Q'),\n",
    "    (2025, 'Saudi Arabian Grand Prix', 'Q'),\n",
    "    (2025, 'Australian Grand Prix', 'Q'),\n",
    "    (2025, 'Japanese Grand Prix', 'Q'),\n",
    "    (2025, 'Chinese Grand Prix', 'Q'),\n",
    "    (2025, 'Miami Grand Prix', 'Q'),\n",
    "    (2025, 'Emilia Romagna Grand Prix', 'Q'),\n",
    "    (2025, 'Monaco Grand Prix', 'Q'),\n",
    "    (2025, 'Canadian Grand Prix', 'Q'),\n",
    "    (2025, 'Spanish Grand Prix', 'Q'),\n",
    "    \n",
    "    # 2025 Races\n",
    "    (2025, 'Bahrain Grand Prix', 'R'),\n",
    "    (2025, 'Saudi Arabian Grand Prix', 'R'),\n",
    "    (2025, 'Australian Grand Prix', 'R'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715abe79",
   "metadata": {},
   "source": [
    "## Run Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad33e83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "[2024] Bahrain Grand Prix - QUALIFYING\n",
      "======================================================================\n",
      "MAE: 1.30  Bias: +0.00  ¬±1: 55%  CI: 100%\n",
      "\n",
      "======================================================================\n",
      "[2024] Saudi Arabian Grand Prix - QUALIFYING\n",
      "======================================================================\n",
      "MAE: 1.80  Bias: +0.00  ¬±1: 35%  CI: 95%\n",
      "\n",
      "======================================================================\n",
      "[2024] Australian Grand Prix - QUALIFYING\n",
      "======================================================================\n",
      "MAE: 1.50  Bias: -0.39  ¬±1: 61%  CI: 94%\n",
      "\n",
      "======================================================================\n",
      "[2024] Japanese Grand Prix - QUALIFYING\n",
      "======================================================================\n",
      "MAE: 1.80  Bias: +0.00  ¬±1: 60%  CI: 75%\n",
      "\n",
      "======================================================================\n",
      "[2024] Chinese Grand Prix - QUALIFYING\n",
      "======================================================================\n",
      "MAE: 2.30  Bias: +0.00  ¬±1: 50%  CI: 75%\n",
      "\n",
      "======================================================================\n",
      "[2024] Miami Grand Prix - QUALIFYING\n",
      "======================================================================\n",
      "MAE: 1.80  Bias: +0.00  ¬±1: 50%  CI: 85%\n",
      "\n",
      "======================================================================\n",
      "[2024] Emilia Romagna Grand Prix - QUALIFYING\n",
      "======================================================================\n",
      "MAE: 2.00  Bias: +0.00  ¬±1: 55%  CI: 80%\n",
      "\n",
      "======================================================================\n",
      "[2024] Monaco Grand Prix - QUALIFYING\n",
      "======================================================================\n",
      "MAE: 1.90  Bias: +0.50  ¬±1: 50%  CI: 80%\n",
      "\n",
      "======================================================================\n",
      "[2024] Canadian Grand Prix - QUALIFYING\n",
      "======================================================================\n",
      "MAE: 2.00  Bias: +0.00  ¬±1: 40%  CI: 90%\n",
      "\n",
      "======================================================================\n",
      "[2024] Spanish Grand Prix - QUALIFYING\n",
      "======================================================================\n",
      "MAE: 1.50  Bias: +0.00  ¬±1: 50%  CI: 85%\n",
      "\n",
      "======================================================================\n",
      "[2024] Bahrain Grand Prix - RACE\n",
      "======================================================================\n",
      "MAE: 1.20  Bias: +0.00  ¬±1: 55%  CI: 95%\n",
      "\n",
      "======================================================================\n",
      "[2024] Saudi Arabian Grand Prix - RACE\n",
      "======================================================================\n",
      "MAE: 1.80  Bias: +0.00  ¬±1: 50%  CI: 85%\n",
      "\n",
      "======================================================================\n",
      "[2024] Australian Grand Prix - RACE\n",
      "======================================================================\n",
      "MAE: 1.33  Bias: -0.44  ¬±1: 72%  CI: 83%\n",
      "\n",
      "======================================================================\n",
      "[2025] Bahrain Grand Prix - QUALIFYING\n",
      "======================================================================\n",
      "MAE: 2.20  Bias: +0.00  ¬±1: 15%  CI: 100%\n",
      "\n",
      "======================================================================\n",
      "[2025] Saudi Arabian Grand Prix - QUALIFYING\n",
      "======================================================================\n",
      "MAE: 1.90  Bias: +0.00  ¬±1: 45%  CI: 85%\n",
      "\n",
      "======================================================================\n",
      "[2025] Australian Grand Prix - QUALIFYING\n",
      "======================================================================\n",
      "MAE: 2.70  Bias: +0.00  ¬±1: 40%  CI: 60%\n",
      "\n",
      "======================================================================\n",
      "[2025] Japanese Grand Prix - QUALIFYING\n",
      "======================================================================\n",
      "MAE: 2.80  Bias: +0.00  ¬±1: 20%  CI: 70%\n",
      "\n",
      "======================================================================\n",
      "[2025] Chinese Grand Prix - QUALIFYING\n",
      "======================================================================\n",
      "MAE: 2.10  Bias: +0.00  ¬±1: 60%  CI: 75%\n",
      "\n",
      "======================================================================\n",
      "[2025] Miami Grand Prix - QUALIFYING\n",
      "======================================================================\n",
      "MAE: 1.90  Bias: +0.00  ¬±1: 50%  CI: 80%\n",
      "\n",
      "======================================================================\n",
      "[2025] Emilia Romagna Grand Prix - QUALIFYING\n",
      "======================================================================\n",
      "MAE: 2.70  Bias: +0.00  ¬±1: 45%  CI: 65%\n",
      "\n",
      "======================================================================\n",
      "[2025] Monaco Grand Prix - QUALIFYING\n",
      "======================================================================\n",
      "MAE: 2.10  Bias: +0.00  ¬±1: 50%  CI: 80%\n",
      "\n",
      "======================================================================\n",
      "[2025] Canadian Grand Prix - QUALIFYING\n",
      "======================================================================\n",
      "MAE: 2.80  Bias: +0.00  ¬±1: 30%  CI: 70%\n",
      "\n",
      "======================================================================\n",
      "[2025] Spanish Grand Prix - QUALIFYING\n",
      "======================================================================\n",
      "MAE: 2.80  Bias: +0.00  ¬±1: 40%  CI: 65%\n",
      "\n",
      "======================================================================\n",
      "[2025] Bahrain Grand Prix - RACE\n",
      "======================================================================\n",
      "MAE: 1.60  Bias: +0.00  ¬±1: 60%  CI: 90%\n",
      "\n",
      "======================================================================\n",
      "[2025] Saudi Arabian Grand Prix - RACE\n",
      "======================================================================\n",
      "MAE: 1.80  Bias: +0.00  ¬±1: 50%  CI: 90%\n",
      "\n",
      "======================================================================\n",
      "[2025] Australian Grand Prix - RACE\n",
      "======================================================================\n",
      "MAE: 3.70  Bias: +0.00  ¬±1: 15%  CI: 55%\n",
      "\n",
      "üü¢ Validated 26 sessions\n"
     ]
    }
   ],
   "source": [
    "# Run validation on all test sessions\n",
    "all_results = []\n",
    "\n",
    "for year, event, session_type in test_sessions:\n",
    "    result = validate_session(year, event, session_type)\n",
    "    if result:\n",
    "        all_results.append(result)\n",
    "\n",
    "print(f\"\\nüü¢ Validated {len(all_results)} sessions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7c2e7c",
   "metadata": {},
   "source": [
    "## Overall Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "858b72cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "OVERALL VALIDATION SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Across 26 sessions:\n",
      "  MAE:          2.05 positions\n",
      "  Bias:         -0.01 positions\n",
      "  ¬±1 position:  46.3%\n",
      "  ¬±2 positions: 68.5%\n",
      "  ¬±3 positions: 81.1%\n",
      "  CI coverage:  81.1%\n",
      "\n",
      "üí° INTERPRETATION:\n",
      "  üü¢ Low bias (-0.01) - predictions are well-calibrated\n",
      "  üü¢ Low MAE (2.05) - good accuracy\n",
      "  üü¢ Good CI coverage (81%) - uncertainty well-calibrated\n"
     ]
    }
   ],
   "source": [
    "if all_results:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"OVERALL VALIDATION SUMMARY\")\n",
    "    print('='*70)\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    mae = np.mean([r['mae'] for r in all_results])\n",
    "    bias = np.mean([r['bias'] for r in all_results])\n",
    "    acc1 = np.mean([r['accuracy_1'] for r in all_results])\n",
    "    acc2 = np.mean([r['accuracy_2'] for r in all_results])\n",
    "    acc3 = np.mean([r['accuracy_3'] for r in all_results])\n",
    "    ci_cov = np.mean([r['ci_coverage'] for r in all_results])\n",
    "    \n",
    "    print(f\"\\nAcross {len(all_results)} sessions:\")\n",
    "    print(f\"  MAE:          {mae:.2f} positions\")\n",
    "    print(f\"  Bias:         {bias:+.2f} positions\")\n",
    "    print(f\"  ¬±1 position:  {acc1*100:.1f}%\")\n",
    "    print(f\"  ¬±2 positions: {acc2*100:.1f}%\")\n",
    "    print(f\"  ¬±3 positions: {acc3*100:.1f}%\")\n",
    "    print(f\"  CI coverage:  {ci_cov*100:.1f}%\")\n",
    "    \n",
    "    # Interpretation\n",
    "    print(f\"\\nüí° INTERPRETATION:\")\n",
    "    \n",
    "    if abs(bias) < 0.5:\n",
    "        print(f\"  üü¢ Low bias ({bias:+.2f}) - predictions are well-calibrated\")\n",
    "    elif bias > 0:\n",
    "        print(f\"  ‚ö†Ô∏è  Positive bias ({bias:+.2f}) - over-predicting positions\")\n",
    "    else:\n",
    "        print(f\"  ‚ö†Ô∏è  Negative bias ({bias:+.2f}) - under-predicting positions\")\n",
    "    \n",
    "    if mae < 2.5:\n",
    "        print(f\"  üü¢ Low MAE ({mae:.2f}) - good accuracy\")\n",
    "    elif mae < 3.5:\n",
    "        print(f\"  ‚ö†Ô∏è  Moderate MAE ({mae:.2f}) - room for improvement\")\n",
    "    else:\n",
    "        print(f\"  üî¥ High MAE ({mae:.2f}) - needs work\")\n",
    "    \n",
    "    if ci_cov > 0.8:\n",
    "        print(f\"  üü¢ Good CI coverage ({ci_cov*100:.0f}%) - uncertainty well-calibrated\")\n",
    "    else:\n",
    "        print(f\"  ‚ö†Ô∏è  Low CI coverage ({ci_cov*100:.0f}%) - confidence intervals too narrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f24ba9",
   "metadata": {},
   "source": [
    "## Performance by Experience Tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eef1af42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PERFORMANCE BY EXPERIENCE TIER\n",
      "======================================================================\n",
      "\n",
      "Tier                 N      MAE     Bias     ¬±1     ¬±2     CI\n",
      "----------------------------------------------------------------------\n",
      "DEVELOPING         115     2.25    -1.16  43.5%  66.1%  78.3%\n",
      "ESTABLISHED        336     1.96    +0.08  47.3%  69.6%  82.4%\n",
      "VETERAN             65     2.23    +1.55  44.6%  66.2%  78.5%\n",
      "\n",
      "üí° TIER INSIGHTS:\n",
      "  üü¢ Similar accuracy across tiers - good!\n"
     ]
    }
   ],
   "source": [
    "# Combine all comparisons\n",
    "all_comps = []\n",
    "for r in all_results:\n",
    "    all_comps.extend(r['comparisons'])\n",
    "\n",
    "comp_df = pd.DataFrame(all_comps)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"PERFORMANCE BY EXPERIENCE TIER\")\n",
    "print('='*70)\n",
    "\n",
    "print(f\"\\n{'Tier':<15} {'N':>6} {'MAE':>8} {'Bias':>8} {'¬±1':>6} {'¬±2':>6} {'CI':>6}\")\n",
    "print('-'*70)\n",
    "\n",
    "for tier in ['rookie', 'developing', 'established', 'veteran']:\n",
    "    tier_data = comp_df[comp_df['tier'] == tier]\n",
    "    if len(tier_data) > 0:\n",
    "        n = len(tier_data)\n",
    "        tier_mae = tier_data['abs_error'].mean()\n",
    "        tier_bias = tier_data['error'].mean()\n",
    "        tier_acc1 = (tier_data['abs_error'] <= 1).mean() * 100\n",
    "        tier_acc2 = (tier_data['abs_error'] <= 2).mean() * 100\n",
    "        tier_ci = tier_data['in_ci'].mean() * 100\n",
    "        \n",
    "        print(f\"{tier.upper():<15} {n:>6} {tier_mae:>8.2f} {tier_bias:>+8.2f} \"\n",
    "              f\"{tier_acc1:>5.1f}% {tier_acc2:>5.1f}% {tier_ci:>5.1f}%\")\n",
    "\n",
    "# Tier insights\n",
    "print(f\"\\nüí° TIER INSIGHTS:\")\n",
    "\n",
    "rookie_mae = comp_df[comp_df['tier'] == 'rookie']['abs_error'].mean() if len(comp_df[comp_df['tier'] == 'rookie']) > 0 else 0\n",
    "veteran_mae = comp_df[comp_df['tier'] == 'veteran']['abs_error'].mean() if len(comp_df[comp_df['tier'] == 'veteran']) > 0 else 0\n",
    "\n",
    "if rookie_mae > veteran_mae * 1.5:\n",
    "    print(f\"  ‚ö†Ô∏è  Rookies have much higher error ({rookie_mae:.2f} vs {veteran_mae:.2f})\")\n",
    "    print(f\"     ‚Üí Consider increasing rookie uncertainty in driver_ranker.py\")\n",
    "elif rookie_mae > veteran_mae:\n",
    "    print(f\"  üü¢ Rookies slightly less accurate ({rookie_mae:.2f} vs {veteran_mae:.2f}) - expected\")\n",
    "else:\n",
    "    print(f\"  üü¢ Similar accuracy across tiers - good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06b8d00",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "895eba5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "WORST PREDICTIONS (Top 10)\n",
      "======================================================================\n",
      "\n",
      "Driver     Pred Actual   Error Tier        \n",
      "--------------------------------------------------\n",
      "LAW        10.0     20   -10.0 established \n",
      "TSU        10.0     20   -10.0 developing  \n",
      "TSU        10.0     20   -10.0 developing  \n",
      "TSU        10.0     19    -9.0 developing  \n",
      "LAW         6.0     15    -9.0 established \n",
      "HAM        10.0     18    -8.0 developing  \n",
      "VER        11.0      3    +8.0 veteran     \n",
      "STR        10.0     18    -8.0 established \n",
      "SAI        10.0     18    -8.0 established \n",
      "VER         9.0      2    +7.0 veteran     \n",
      "\n",
      "üí° ERROR PATTERNS:\n",
      "  üü¢ Errors distributed across grid\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*70}\")\n",
    "print(\"WORST PREDICTIONS (Top 10)\")\n",
    "print('='*70)\n",
    "\n",
    "worst = comp_df.nlargest(10, 'abs_error')[['driver', 'predicted', 'actual', 'error', 'tier']]\n",
    "\n",
    "print(f\"\\n{'Driver':<8} {'Pred':>6} {'Actual':>6} {'Error':>7} {'Tier':<12}\")\n",
    "print('-'*50)\n",
    "\n",
    "for _, row in worst.iterrows():\n",
    "    print(f\"{row['driver']:<8} {row['predicted']:>6.1f} {row['actual']:>6} \"\n",
    "          f\"{row['error']:>+7.1f} {row['tier']:<12}\")\n",
    "\n",
    "# Error patterns\n",
    "print(f\"\\nüí° ERROR PATTERNS:\")\n",
    "\n",
    "# Check if errors cluster by position range\n",
    "top10_errors = comp_df[comp_df['actual'] <= 10]['error'].mean()\n",
    "bottom10_errors = comp_df[comp_df['actual'] > 10]['error'].mean()\n",
    "\n",
    "if abs(top10_errors) > abs(bottom10_errors) + 0.5:\n",
    "    print(f\"  ‚ö†Ô∏è  Larger errors in top 10 (avg: {top10_errors:+.2f})\")\n",
    "elif abs(bottom10_errors) > abs(top10_errors) + 0.5:\n",
    "    print(f\"  ‚ö†Ô∏è  Larger errors in bottom 10 (avg: {bottom10_errors:+.2f})\")\n",
    "else:\n",
    "    print(f\"  üü¢ Errors distributed across grid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1917f3",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66b5b3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üü¢ Saved validation results to ../data/processed/testing_files/validation/driver_position_validation.json\n"
     ]
    }
   ],
   "source": [
    "def to_jsonable(x):\n",
    "    \"\"\"Convert numpy/pandas types to JSON-serializable Python types.\"\"\"\n",
    "    if isinstance(x, dict):\n",
    "        return {str(k): to_jsonable(v) for k, v in x.items()}\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        return [to_jsonable(v) for v in x]\n",
    "    if isinstance(x, np.generic):\n",
    "        return x.item()\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return x.tolist()\n",
    "    if isinstance(x, (pd.Timestamp, pd.Timedelta)):\n",
    "        return x.isoformat()\n",
    "    if x is pd.NA:\n",
    "        return None\n",
    "    return x\n",
    "\n",
    "\n",
    "# Package results\n",
    "output = {\n",
    "    'summary': {\n",
    "        'n_sessions': len(all_results),\n",
    "        'n_predictions': len(comp_df),\n",
    "        'mae': mae,\n",
    "        'bias': bias,\n",
    "        'accuracy_1': acc1,\n",
    "        'accuracy_2': acc2,\n",
    "        'accuracy_3': acc3,\n",
    "        'ci_coverage': ci_cov\n",
    "    },\n",
    "    'by_tier': {\n",
    "        tier: {\n",
    "            'n': len(comp_df[comp_df['tier'] == tier]),\n",
    "            'mae': comp_df[comp_df['tier'] == tier]['abs_error'].mean() \n",
    "                   if len(comp_df[comp_df['tier'] == tier]) > 0 else None,\n",
    "            'bias': comp_df[comp_df['tier'] == tier]['error'].mean() \n",
    "                    if len(comp_df[comp_df['tier'] == tier]) > 0 else None\n",
    "        }\n",
    "        for tier in ['rookie', 'developing', 'established', 'veteran']\n",
    "    },\n",
    "    'session_results': all_results\n",
    "}\n",
    "\n",
    "output = to_jsonable(output)\n",
    "\n",
    "# Save\n",
    "output_path = Path('../data/processed/testing_files/validation/driver_position_validation.json')\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(output, f, indent=2)\n",
    "\n",
    "print(f\"üü¢ Saved validation results to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
