{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# 02 Feature Engineering - Extract telemetry features\n",
    "\n",
    "Goal: Build a pipeline that turns raw lap data into features I can feed into the Bayesian model.\n",
    "\n",
    "Pipeline flow:\n",
    "1. Single lap â†’ extract telemetry features (speed, throttle, braking, etc.)\n",
    "2. Driver session â†’ aggregate all their laps\n",
    "3. Full session â†’ calculate relative performance (who's fastest?)\n",
    "4. Export â†’ ready for predictions\n",
    "\n",
    "This will move to `src/` later as production code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastf1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.append(str(project_root))\n",
    "logging.getLogger(\"fastf1\").setLevel(logging.ERROR)\n",
    "cache_dir = Path(f'{project_root}/data/raw/.fastf1_cache')\n",
    "cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "fastf1.Cache.enable_cache(str(cache_dir))\n",
    "\n",
    "output_dir = Path(f'{project_root}/data/processed/testing_files/')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "season = 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1",
   "metadata": {},
   "source": [
    "## Part 1: Single lap features\n",
    "\n",
    "Core building block - extract features from one lap of telemetry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lap_extractor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: Extract features from Verstappen's lap in 2025 testing\n",
      "Lap 14.0: 0 days 00:01:39.710000\n",
      "\n",
      "Extracted 13 features:\n",
      "  slow_corner_speed: 89.7\n",
      "  medium_corner_speed: 152.2\n",
      "  high_corner_speed: 224.3\n",
      "  pct_full_throttle: 46.4\n",
      "  avg_throttle: 63.2\n",
      "\n",
      "ðŸŸ¢ Single lap extraction works\n"
     ]
    }
   ],
   "source": [
    "class LapFeatureExtractor:\n",
    "    \"\"\"Extract telemetry features from a single F1 lap.\"\"\"\n",
    "    \n",
    "    def __init__(self, corner_speed_thresholds=None):\n",
    "        \"\"\"\n",
    "        Corner speed thresholds for classification.\n",
    "        Default: slow <100, medium 100-200, high 200-250 km/h\n",
    "        \"\"\"\n",
    "        if corner_speed_thresholds is None:\n",
    "            self.corner_thresholds = {\n",
    "                'slow': (0, 100),\n",
    "                'medium': (100, 200),\n",
    "                'high': (200, 250)\n",
    "            }\n",
    "        else:\n",
    "            self.corner_thresholds = corner_speed_thresholds\n",
    "    \n",
    "    def extract_corner_speeds(self, telemetry):\n",
    "        \"\"\"Average speed in slow/medium/high-speed corners.\"\"\"\n",
    "        # Corners are anywhere under 250 km/h (arbitrary but works)\n",
    "        corners = telemetry[telemetry['Speed'] < 250]\n",
    "        \n",
    "        speeds = {}\n",
    "        for corner_type, (min_speed, max_speed) in self.corner_thresholds.items():\n",
    "            mask = (corners['Speed'] >= min_speed) & (corners['Speed'] < max_speed)\n",
    "            corner_data = corners[mask]\n",
    "            \n",
    "            if len(corner_data) > 0:\n",
    "                speeds[f'{corner_type}_corner_speed'] = corner_data['Speed'].mean()\n",
    "            else:\n",
    "                speeds[f'{corner_type}_corner_speed'] = np.nan\n",
    "        \n",
    "        return speeds\n",
    "    \n",
    "    def extract_throttle_metrics(self, telemetry):\n",
    "        \"\"\"Throttle usage - percentage at full throttle, average, smoothness.\"\"\"\n",
    "        throttle = telemetry['Throttle']\n",
    "        \n",
    "        return {\n",
    "            'pct_full_throttle': (throttle == 100).sum() / len(throttle) * 100,\n",
    "            'avg_throttle': throttle.mean(),\n",
    "            'throttle_smoothness': throttle.std()  # lower = smoother\n",
    "        }\n",
    "    \n",
    "    def extract_braking_metrics(self, telemetry):\n",
    "        \"\"\"Braking zones and intensity.\"\"\"\n",
    "        brake = telemetry['Brake']\n",
    "        \n",
    "        # Count braking zones (transitions from 0 to >0)\n",
    "        braking_points = ((brake > 0) & (brake.shift(1) == 0)).sum()\n",
    "        \n",
    "        return {\n",
    "            'braking_pct': (brake > 0).sum() / len(brake) * 100,\n",
    "            'braking_zones': braking_points,\n",
    "            'avg_brake_intensity': brake[brake > 0].mean() if (brake > 0).any() else 0\n",
    "        }\n",
    "    \n",
    "    def extract_straight_line_speed(self, telemetry):\n",
    "        \"\"\"Top speed and speed at full throttle.\"\"\"\n",
    "        full_throttle = telemetry[telemetry['Throttle'] == 100]\n",
    "        \n",
    "        # Max gear (usually 8th) indicates straight-line running\n",
    "        max_gear = telemetry['nGear'].max()\n",
    "        top_gear = telemetry[telemetry['nGear'] == max_gear]\n",
    "        \n",
    "        return {\n",
    "            'avg_speed_full_throttle': full_throttle['Speed'].mean() if len(full_throttle) > 0 else np.nan,\n",
    "            'max_speed': telemetry['Speed'].max(),\n",
    "            'pct_at_max_gear': len(top_gear) / len(telemetry) * 100\n",
    "        }\n",
    "    \n",
    "    def extract_drs_usage(self, telemetry):\n",
    "        \"\"\"How much DRS was available and used.\"\"\"\n",
    "        drs = telemetry['DRS']\n",
    "        return {'drs_active_pct': (drs > 0).sum() / len(drs) * 100}\n",
    "    \n",
    "    def extract_features(self, lap) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Extract all features from a lap.\n",
    "        Returns dict of feature_name -> value.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            telemetry = lap.get_telemetry()\n",
    "            \n",
    "            if telemetry is None or len(telemetry) == 0:\n",
    "                return {}\n",
    "            \n",
    "            # Combine all feature extractors\n",
    "            features = {}\n",
    "            features.update(self.extract_corner_speeds(telemetry))\n",
    "            features.update(self.extract_throttle_metrics(telemetry))\n",
    "            features.update(self.extract_braking_metrics(telemetry))\n",
    "            features.update(self.extract_straight_line_speed(telemetry))\n",
    "            features.update(self.extract_drs_usage(telemetry))\n",
    "            \n",
    "            return features\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Sometimes telemetry fails to load\n",
    "            return {}\n",
    "\n",
    "\n",
    "# Quick test on a real lap\n",
    "print(f\"\\nTest: Extract features from Verstappen's lap in {season} testing\")\n",
    "\n",
    "session = fastf1.get_session(season, 'Testing', 1)\n",
    "session.load()\n",
    "\n",
    "ver_laps = session.laps.pick_drivers('VER')\n",
    "lap = ver_laps.iloc[len(ver_laps) // 2] if len(ver_laps) > 0 else ver_laps.iloc[0]\n",
    "\n",
    "extractor = LapFeatureExtractor()\n",
    "features = extractor.extract_features(lap)\n",
    "\n",
    "print(f\"Lap {lap['LapNumber']}: {lap['LapTime']}\")\n",
    "print(f\"\\nExtracted {len(features)} features:\")\n",
    "for k, v in list(features.items())[:5]:\n",
    "    print(f\"  {k}: {v:.1f}\")\n",
    "\n",
    "print(\"\\nðŸŸ¢ Single lap extraction works\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2",
   "metadata": {},
   "source": [
    "## Part 2: Aggregate driver session\n",
    "\n",
    "One driver does ~60 laps in a session. I need to aggregate them into representative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "session_aggregator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: Extract features for all drivers in FP1\n",
      "\n",
      "Extracted features for 20 drivers\n",
      "Features per driver: 32\n",
      "\n",
      "Fastest 3:\n",
      "   driver_code         team  fastest_lap  clean_laps\n",
      "1          NOR      McLaren       93.294          14\n",
      "11         HUL  Kick Sauber       93.549          15\n",
      "18         PIA      McLaren       93.573          17\n",
      "\n",
      "ðŸŸ¢ Session aggregation works\n"
     ]
    }
   ],
   "source": [
    "class SessionFeatureAggregator:\n",
    "    \"\"\"Aggregate lap-level features into session-level features for a driver.\"\"\"\n",
    "    \n",
    "    def __init__(self, lap_extractor):\n",
    "        self.lap_extractor = lap_extractor\n",
    "    \n",
    "    def filter_clean_laps(self, laps):\n",
    "        \"\"\"\n",
    "        Remove outliers and invalid laps.\n",
    "        Keep laps where: in-lap, out-lap, yellow flags, accidents filtered out.\n",
    "        \"\"\"\n",
    "        # Basic filters\n",
    "        clean = laps[\n",
    "            (laps['IsAccurate'] == True) &\n",
    "            (laps['TrackStatus'] == '1')  # Green flag\n",
    "        ].copy()\n",
    "        \n",
    "        # Remove statistical outliers (more than 3 std from median)\n",
    "        if len(clean) > 5:\n",
    "            lap_times = clean['LapTime'].dt.total_seconds()\n",
    "            median = lap_times.median()\n",
    "            std = lap_times.std()\n",
    "            \n",
    "            clean = clean[abs(lap_times - median) < 3 * std]\n",
    "        \n",
    "        return clean\n",
    "    \n",
    "    def extract_driver_session(self, laps) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Extract features for one driver's session.\n",
    "        Returns aggregated features (median across clean laps).\n",
    "        \"\"\"\n",
    "        if len(laps) == 0:\n",
    "            return {}\n",
    "\n",
    "        driver_info = {\n",
    "            'driver_number': str(laps.iloc[0]['DriverNumber']),\n",
    "            'driver_code': laps.iloc[0]['Driver'],\n",
    "            'team': laps.iloc[0]['Team'],\n",
    "            'total_laps': len(laps)\n",
    "        }\n",
    "\n",
    "        clean_laps = self.filter_clean_laps(laps)\n",
    "        driver_info['clean_laps'] = len(clean_laps)\n",
    "\n",
    "        if len(clean_laps) == 0:\n",
    "            driver_info['fastest_lap'] = np.nan\n",
    "            return driver_info\n",
    "\n",
    "        # Only laps with a real laptime\n",
    "        timed_laps = clean_laps[clean_laps['LapTime'].notna()]\n",
    "        if len(timed_laps) == 0:\n",
    "            driver_info['fastest_lap'] = np.nan\n",
    "            return driver_info\n",
    "\n",
    "        fastest = timed_laps.pick_fastest()\n",
    "        if fastest is None or pd.isna(fastest.get('LapTime', np.nan)):\n",
    "            driver_info['fastest_lap'] = np.nan\n",
    "            return driver_info\n",
    "\n",
    "        driver_info['fastest_lap'] = fastest['LapTime'].total_seconds()\n",
    "\n",
    "        lap_features = []\n",
    "        for _, lap in timed_laps.iterrows():\n",
    "            features = self.lap_extractor.extract_features(lap)\n",
    "            if features:\n",
    "                lap_features.append(features)\n",
    "\n",
    "        if len(lap_features) == 0:\n",
    "            return driver_info\n",
    "\n",
    "        df = pd.DataFrame(lap_features)\n",
    "        aggregated = df.median(numeric_only=True).to_dict()\n",
    "\n",
    "        for col in df.columns:\n",
    "            aggregated[f'{col}_std'] = df[col].std()\n",
    "\n",
    "        return {**driver_info, **aggregated}\n",
    "    \n",
    "    def extract_all_drivers(self, session) -> pd.DataFrame:\n",
    "        \"\"\"Extract features for all drivers in a session.\"\"\"\n",
    "        driver_features = []\n",
    "        \n",
    "        for driver in session.laps['Driver'].unique():\n",
    "            driver_laps = session.laps.pick_drivers(driver)\n",
    "            features = self.extract_driver_session(driver_laps)\n",
    "            \n",
    "            if features and 'fastest_lap' in features:\n",
    "                driver_features.append(features)\n",
    "        \n",
    "        return pd.DataFrame(driver_features)\n",
    "\n",
    "\n",
    "# Test on full session\n",
    "print(\"\\nTest: Extract features for all drivers in FP1\")\n",
    "\n",
    "aggregator = SessionFeatureAggregator(extractor)\n",
    "session_features = aggregator.extract_all_drivers(session)\n",
    "\n",
    "print(f\"\\nExtracted features for {len(session_features)} drivers\")\n",
    "print(f\"Features per driver: {len(session_features.columns)}\")\n",
    "print(f\"\\nFastest 3:\")\n",
    "print(session_features.nsmallest(3, 'fastest_lap')[['driver_code', 'team', 'fastest_lap', 'clean_laps']])\n",
    "\n",
    "print(\"\\nðŸŸ¢ Session aggregation works\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3",
   "metadata": {},
   "source": [
    "## Part 3: Relative performance\n",
    "\n",
    "Absolute lap times don't mean much (depends on track, conditions, etc.).\n",
    "I need relative performance - how fast is this driver compared to the field?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "relative_perf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: Calculate relative performance\n",
      "\n",
      "Added relative features:\n",
      "  29 relative columns\n",
      "\n",
      "Top 3 by fastest lap percentile:\n",
      "   driver_code  fastest_lap  fastest_lap_rel  fastest_lap_pct\n",
      "7          LEC       96.080           1.7295            100.0\n",
      "16         SAI       95.874           1.5235             95.0\n",
      "5          ANT       94.737           0.3865             90.0\n",
      "\n",
      "ðŸŸ¢ Relative performance works\n"
     ]
    }
   ],
   "source": [
    "class RelativePerformanceCalculator:\n",
    "    \"\"\"Convert absolute features to relative performance vs field.\"\"\"\n",
    "    \n",
    "    def __init__(self, use_median=True):\n",
    "        \"\"\"\n",
    "        use_median: If True, normalize to median (robust to outliers).\n",
    "                   If False, normalize to mean.\n",
    "        \"\"\"\n",
    "        self.use_median = use_median\n",
    "    \n",
    "    def normalize_features(self, features_df):\n",
    "        \"\"\"\n",
    "        Add relative features: difference from field median/mean.\n",
    "        Prefix: 'fastest_lap_rel', 'avg_throttle_rel', etc.\n",
    "        \"\"\"\n",
    "        df = features_df.copy()\n",
    "        \n",
    "        # Identify numeric columns (skip metadata like driver_code)\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        \n",
    "        for col in numeric_cols:\n",
    "            if df[col].notna().sum() < 2:\n",
    "                continue  # Skip if not enough data\n",
    "            \n",
    "            if self.use_median:\n",
    "                baseline = df[col].median()\n",
    "            else:\n",
    "                baseline = df[col].mean()\n",
    "            \n",
    "            df[f'{col}_rel'] = df[col] - baseline\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def add_percentile_ranks(self, features_df):\n",
    "        \"\"\"\n",
    "        Add percentile ranks for key features.\n",
    "        Example: fastest_lap_pct = 95 means faster than 95% of field.\n",
    "        \"\"\"\n",
    "        df = features_df.copy()\n",
    "        \n",
    "        # Lower is better for lap times\n",
    "        if 'fastest_lap' in df.columns:\n",
    "            df['fastest_lap_pct'] = df['fastest_lap'].rank(pct=True, ascending=True) * 100\n",
    "        \n",
    "        # Higher is better for speed metrics\n",
    "        speed_cols = [col for col in df.columns if 'speed' in col.lower() and '_rel' not in col]\n",
    "        for col in speed_cols:\n",
    "            if col in df.columns:\n",
    "                df[f'{col}_pct'] = df[col].rank(pct=True, ascending=False) * 100\n",
    "        \n",
    "        return df\n",
    "\n",
    "\n",
    "# Test relative performance\n",
    "print(\"\\nTest: Calculate relative performance\")\n",
    "\n",
    "rel_calc = RelativePerformanceCalculator(use_median=True)\n",
    "normalized = rel_calc.normalize_features(session_features)\n",
    "with_ranks = rel_calc.add_percentile_ranks(normalized)\n",
    "\n",
    "print(f\"\\nAdded relative features:\")\n",
    "rel_cols = [col for col in with_ranks.columns if '_rel' in col]\n",
    "print(f\"  {len(rel_cols)} relative columns\")\n",
    "\n",
    "print(f\"\\nTop 3 by fastest lap percentile:\")\n",
    "print(with_ranks.nlargest(3, 'fastest_lap_pct')[['driver_code', 'fastest_lap', 'fastest_lap_rel', 'fastest_lap_pct']])\n",
    "\n",
    "print(\"\\nðŸŸ¢ Relative performance works\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4",
   "metadata": {},
   "source": [
    "## Part 4: Production pipeline\n",
    "\n",
    "Put it all together in one clean pipeline class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pipeline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: Process all 2025 testing sessions\n",
      "Processing 1/3: United States Grand Prix - Practice 1\n",
      "Processing 2/3: United States Grand Prix - Sprint Qualifying\n",
      "Processing 3/3: United States Grand Prix - Sprint\n",
      "\n",
      "ðŸŸ¢ Processed 3 sessions\n",
      "  60 total rows, 20 drivers\n",
      "\n",
      "Dataset shape: (60, 76)\n",
      "Feature completeness: 91.5%\n",
      "\n",
      "ðŸŸ¢ Production pipeline works\n"
     ]
    }
   ],
   "source": [
    "class F1FeaturePipeline:\n",
    "    \"\"\"\n",
    "    Complete feature extraction pipeline.\n",
    "    \n",
    "    Usage:\n",
    "        pipeline = F1FeaturePipeline()\n",
    "        features = pipeline.process_session(session)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.lap_extractor = LapFeatureExtractor()\n",
    "        self.session_aggregator = SessionFeatureAggregator(self.lap_extractor)\n",
    "        self.rel_calculator = RelativePerformanceCalculator(use_median=True)\n",
    "    \n",
    "    def process_session(self, session, add_metadata=True):\n",
    "        \"\"\"\n",
    "        Complete pipeline: Session â†’ Features with relative performance.\n",
    "        \n",
    "        Returns DataFrame with one row per driver.\n",
    "        \"\"\"\n",
    "        # Step 1: Extract raw features\n",
    "        features = self.session_aggregator.extract_all_drivers(session)\n",
    "        \n",
    "        if len(features) == 0:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Step 2: Calculate relative performance\n",
    "        normalized = self.rel_calculator.normalize_features(features)\n",
    "        with_ranks = self.rel_calculator.add_percentile_ranks(normalized)\n",
    "        \n",
    "        # Step 3: Add metadata\n",
    "        if add_metadata:\n",
    "            with_ranks['year'] = session.event['EventDate'].year\n",
    "            with_ranks['event'] = session.event['EventName']\n",
    "            with_ranks['session_type'] = session.name\n",
    "            with_ranks['session_date'] = session.date\n",
    "        \n",
    "        return with_ranks\n",
    "    \n",
    "    def process_multiple_sessions(self, sessions, verbose=True):\n",
    "        \"\"\"Process multiple sessions and combine.\"\"\"\n",
    "        all_features = []\n",
    "        \n",
    "        for i, session in enumerate(sessions):\n",
    "            if verbose:\n",
    "                print(f\"Processing {i+1}/{len(sessions)}: {session.event['EventName']} - {session.name}\")\n",
    "            \n",
    "            features = self.process_session(session)\n",
    "            if len(features) > 0:\n",
    "                all_features.append(features)\n",
    "        \n",
    "        if len(all_features) == 0:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        combined = pd.concat(all_features, ignore_index=True)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nðŸŸ¢ Processed {len(all_features)} sessions\")\n",
    "            print(f\"  {len(combined)} total rows, {combined['driver_number'].nunique()} drivers\")\n",
    "        \n",
    "        return combined\n",
    "\n",
    "\n",
    "# Test on testing (3 days)\n",
    "print(f\"\\nTest: Process all {season} testing sessions\")\n",
    "\n",
    "pipeline = F1FeaturePipeline()\n",
    "\n",
    "testing_sessions = []\n",
    "for day in range(1, 4):\n",
    "    s = fastf1.get_session(season, 'Testing', day)\n",
    "    s.load()\n",
    "    testing_sessions.append(s)\n",
    "\n",
    "all_features = pipeline.process_multiple_sessions(testing_sessions)\n",
    "\n",
    "print(f\"\\nDataset shape: {all_features.shape}\")\n",
    "print(f\"Feature completeness: {all_features.notna().mean().mean() * 100:.1f}%\")\n",
    "\n",
    "print(\"\\nðŸŸ¢ Production pipeline works\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export",
   "metadata": {},
   "source": [
    "## Export features\n",
    "\n",
    "Save to parquet for fast loading in Bayesian validation notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "export_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŸ¢ Saved to /Users/tomasz.solis/repos/private-projects/formula1-2026/data/processed/testing_files/2025_testing_features.parquet\n",
      "  Shape: (60, 76)\n",
      "  Size: 73.0 KB\n"
     ]
    }
   ],
   "source": [
    "output_file = output_dir / f'{season}_testing_features.parquet'\n",
    "all_features.to_parquet(output_file, index=False)\n",
    "\n",
    "print(f\"ðŸŸ¢ Saved to {output_file}\")\n",
    "print(f\"  Shape: {all_features.shape}\")\n",
    "print(f\"  Size: {output_file.stat().st_size / 1024:.1f} KB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
