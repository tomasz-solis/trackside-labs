{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 Prediction Bias Analysis\n",
    "\n",
    "Which teams are we systematically over/under-rating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.predictors.team_predictor import rank_teams_for_track\n",
    "from src.utils.team_mapping import canonicalize_team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŸ¢ Loaded: tracks (24), cars (10), results (24 races)\n"
     ]
    }
   ],
   "source": [
    "loaded = []\n",
    "errors = []\n",
    "\n",
    "try:\n",
    "    track_path = Path('../data/processed/testing_files/track_characteristics/2025_track_characteristics.json')\n",
    "    with open(track_path) as f:\n",
    "        all_tracks = json.load(f)['tracks']\n",
    "    loaded.append(f\"tracks ({len(all_tracks)})\")\n",
    "except FileNotFoundError:\n",
    "    errors.append(\"track characteristics\")\n",
    "    all_tracks = []\n",
    "\n",
    "try:\n",
    "    car_path = Path('../data/processed/testing_files/car_characteristics/2025_car_characteristics.json')\n",
    "    with open(car_path) as f:\n",
    "        all_cars = json.load(f)['teams']\n",
    "    loaded.append(f\"cars ({len(all_cars)})\")\n",
    "except FileNotFoundError:\n",
    "    errors.append(\"car characteristics\")\n",
    "    all_cars = []\n",
    "\n",
    "try:\n",
    "    results_path = Path('../data/processed/testing_files/validation/2025_qualifying_results.json')\n",
    "    with open(results_path) as f:\n",
    "        actual_results = json.load(f)\n",
    "    loaded.append(f\"results ({actual_results.get('total_races', 0)} races)\")\n",
    "except FileNotFoundError:\n",
    "    errors.append(\"qualifying results\")\n",
    "    actual_results = {}\n",
    "\n",
    "# Print summary\n",
    "if loaded:\n",
    "    print(f\"ðŸŸ¢ Loaded: {', '.join(loaded)}\")\n",
    "if errors:\n",
    "    print(f\"ðŸ”´  Missing: {', '.join(errors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Position Bias\n",
    "\n",
    "Bias = Predicted Position - Actual Position\n",
    "- Negative bias = Underrating (predicted worse than actual)\n",
    "- Positive bias = Overrating (predicted better than actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŸ¢ Calculated biases for 10 teams\n"
     ]
    }
   ],
   "source": [
    "#Collect all predictions and actuals\n",
    "all_biases = defaultdict(lambda: {'fp1': [], 'fp2': [], 'fp3': [], 'sprint_quali': []})\n",
    "\n",
    "for race_name, race_data in actual_results['races'].items():\n",
    "    if race_name not in all_tracks:\n",
    "        continue\n",
    "    \n",
    "    track_chars = all_tracks[race_name]\n",
    "    weekend_type = race_data['weekend_type']\n",
    "    \n",
    "    # Get actual positions\n",
    "    actual_positions = {}\n",
    "    for pos_data in race_data['positions']:\n",
    "        team = canonicalize_team(pos_data['team'])\n",
    "        actual_positions[team] = pos_data['position']\n",
    "    \n",
    "    # Get predictions for each stage\n",
    "    if weekend_type == 'sprint':\n",
    "        stages = [('post_fp1', 'sprint', 'fp1'), ('post_sprint_quali', 'sprint', 'sprint_quali')]\n",
    "    else:\n",
    "        stages = [('post_fp1', 'normal', 'fp1'), ('post_fp2', 'normal', 'fp2'), ('post_fp3', 'normal', 'fp3')]\n",
    "    \n",
    "    for stage_key, wtype, stage_name in stages:\n",
    "        rankings = rank_teams_for_track(all_cars, track_chars, stage_key, wtype)\n",
    "        \n",
    "        if not rankings:\n",
    "            continue\n",
    "        \n",
    "        # Calculate bias for each team\n",
    "        for pred_pos, (team, score, conf, _) in enumerate(rankings, 1):\n",
    "            team_canonical = canonicalize_team(team)\n",
    "            \n",
    "            if team_canonical in actual_positions:\n",
    "                actual_pos = actual_positions[team_canonical]\n",
    "                bias = pred_pos - actual_pos  # Positive = overrating\n",
    "                all_biases[team_canonical][stage_name].append(bias)\n",
    "\n",
    "print(f\"ðŸŸ¢ Calculated biases for {len(all_biases)} teams\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Bias by Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Position Bias by Team (FP3):\n",
      "======================================================================\n",
      "Negative = Underrating, Positive = Overrating\n",
      "\n",
      "RED BULL             -11.6 positions  UNDERRATED\n",
      "WILLIAMS             -9.9 positions  UNDERRATED\n",
      "ALPINE               -9.6 positions  UNDERRATED\n",
      "AUDI                 -8.4 positions  UNDERRATED\n",
      "ASTON MARTIN         -7.9 positions  UNDERRATED\n",
      "MERCEDES             -7.9 positions  UNDERRATED\n",
      "RB                   -7.6 positions  UNDERRATED\n",
      "HAAS                 -6.8 positions  UNDERRATED\n",
      "FERRARI              -4.3 positions  UNDERRATED\n",
      "MCLAREN              -1.5 positions  UNDERRATED\n"
     ]
    }
   ],
   "source": [
    "# Calculate average bias for each team\n",
    "team_avg_bias = {}\n",
    "\n",
    "for team, stages in all_biases.items():\n",
    "    team_avg_bias[team] = {}\n",
    "    \n",
    "    for stage, biases in stages.items():\n",
    "        if biases:\n",
    "            team_avg_bias[team][stage] = np.mean(biases)\n",
    "        else:\n",
    "            team_avg_bias[team][stage] = None\n",
    "\n",
    "# Show results\n",
    "print(\"Average Position Bias by Team (FP3):\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Negative = Underrating, Positive = Overrating\")\n",
    "print()\n",
    "\n",
    "# Sort by FP3 bias\n",
    "fp3_biases = [(team, data['fp3']) for team, data in team_avg_bias.items() if data.get('fp3') is not None]\n",
    "fp3_biases.sort(key=lambda x: x[1])\n",
    "\n",
    "for team, bias in fp3_biases:\n",
    "    if bias < -1:\n",
    "        status = \"UNDERRATED\"\n",
    "    elif bias > 1:\n",
    "        status = \"OVERRATED\"\n",
    "    else:\n",
    "        status = \"OK\"\n",
    "    \n",
    "    print(f\"{team:<20} {bias:+.1f} positions  {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Evolution (FP1 â†’ FP2 â†’ FP3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias Evolution by Session:\n",
      "======================================================================\n",
      "Team                      FP1      FP2      FP3      Trend\n",
      "----------------------------------------------------------------------\n",
      "ALPINE                   -9.4    -11.7     -9.6     Stable\n",
      "ASTON MARTIN            -10.2    -10.0     -7.9      Worse\n",
      "AUDI                     -8.1    -10.9     -8.4     Stable\n",
      "FERRARI                  -4.0     -6.7     -4.3     Stable\n",
      "HAAS                     -6.7     -6.8     -6.8     Stable\n",
      "MCLAREN                  -2.1     -2.9     -1.5      Worse\n",
      "MERCEDES                 -3.7     -1.2     -7.9     Better\n",
      "RB                       -8.5    -10.6     -7.6      Worse\n",
      "RED BULL                -10.3     -8.3    -11.6     Better\n",
      "WILLIAMS                -12.9     -6.4     -9.9      Worse\n"
     ]
    }
   ],
   "source": [
    "print(\"Bias Evolution by Session:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Team':<20} {'FP1':>8} {'FP2':>8} {'FP3':>8} {'Trend':>10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for team, data in sorted(team_avg_bias.items()):\n",
    "    fp1 = data.get('fp1')\n",
    "    fp2 = data.get('fp2')\n",
    "    fp3 = data.get('fp3')\n",
    "    \n",
    "    if fp1 is None or fp3 is None:\n",
    "        continue\n",
    "    \n",
    "    # Check trend\n",
    "    if abs(fp3 - fp1) < 0.5:\n",
    "        trend = \"Stable\"\n",
    "    elif fp3 > fp1:\n",
    "        trend = \"Worse\"  # More positive = more overrated\n",
    "    else:\n",
    "        trend = \"Better\"\n",
    "    \n",
    "    fp1_str = f\"{fp1:+.1f}\" if fp1 is not None else \"N/A\"\n",
    "    fp2_str = f\"{fp2:+.1f}\" if fp2 is not None else \"N/A\"\n",
    "    fp3_str = f\"{fp3:+.1f}\" if fp3 is not None else \"N/A\"\n",
    "    \n",
    "    print(f\"{team:<20} {fp1_str:>8} {fp2_str:>8} {fp3_str:>8} {trend:>10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which Teams Get Predicted Right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy by Team (Â±2 positions):\n",
      "======================================================================\n",
      "Team                      FP1      FP2      FP3\n",
      "----------------------------------------------------------------------\n",
      "MCLAREN                  62%     67%     72%\n",
      "FERRARI                  46%     17%     33%\n",
      "ASTON MARTIN              8%     11%     11%\n",
      "HAAS                      8%     11%     11%\n",
      "WILLIAMS                  0%     22%      6%\n",
      "RB                        4%      0%      6%\n",
      "MERCEDES                 50%     28%      6%\n",
      "RED BULL                  4%     11%      0%\n",
      "ALPINE                    0%      0%      0%\n",
      "AUDI                      0%      0%      0%\n"
     ]
    }
   ],
   "source": [
    "# Count how often each team is within 2 positions\n",
    "accuracy_by_team = defaultdict(lambda: {'fp1': 0, 'fp2': 0, 'fp3': 0, 'total': 0})\n",
    "\n",
    "for team, stages in all_biases.items():\n",
    "    for stage, biases in stages.items():\n",
    "        if stage == 'sprint_quali':\n",
    "            continue\n",
    "        \n",
    "        total = len(biases)\n",
    "        accurate = sum(1 for b in biases if abs(b) <= 2)  # Within 2 positions\n",
    "        \n",
    "        if total > 0:\n",
    "            accuracy_by_team[team][stage] = accurate / total\n",
    "            accuracy_by_team[team]['total'] = total\n",
    "\n",
    "print(\"Prediction Accuracy by Team (Â±2 positions):\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Team':<20} {'FP1':>8} {'FP2':>8} {'FP3':>8}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for team, data in sorted(accuracy_by_team.items(), key=lambda x: x[1].get('fp3', 0), reverse=True):\n",
    "    fp1 = data.get('fp1', 0)\n",
    "    fp2 = data.get('fp2', 0)\n",
    "    fp3 = data.get('fp3', 0)\n",
    "    \n",
    "    print(f\"{team:<20} {fp1:>7.0%} {fp2:>7.0%} {fp3:>7.0%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Teams Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teams Where FP3 Ruins Prediction:\n",
      "======================================================================\n",
      "MERCEDES             FP1: -3.7  â†’  FP3: -7.9  (Î”: +4.2)\n",
      "RED BULL             FP1: -10.3  â†’  FP3: -11.6  (Î”: +1.3)\n"
     ]
    }
   ],
   "source": [
    "# Find teams where FP3 is much worse than FP1\n",
    "print(\"Teams Where FP3 Ruins Prediction:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for team, data in sorted(team_avg_bias.items()):\n",
    "    fp1 = data.get('fp1')\n",
    "    fp3 = data.get('fp3')\n",
    "    \n",
    "    if fp1 is None or fp3 is None:\n",
    "        continue\n",
    "    \n",
    "    degradation = abs(fp3) - abs(fp1)\n",
    "    \n",
    "    if degradation > 1.0:  # FP3 is more wrong than FP1\n",
    "        print(f\"{team:<20} FP1: {fp1:+.1f}  â†’  FP3: {fp3:+.1f}  (Î”: {degradation:+.1f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelnel": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
