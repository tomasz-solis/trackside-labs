{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "# 15 Blended Predictions - Model + Actual FP Data\n",
    "\n",
    "**Normal Weekend:**\n",
    "- Friday: FP1, FP2\n",
    "- Saturday AM: FP3\n",
    "- **Lineup lock before Qualifying** ‚Üê Use FP3 data!\n",
    "\n",
    "**Sprint Weekend:**\n",
    "- Friday: FP1, Sprint Quali\n",
    "- **Lineup lock before Sprint** ‚Üê Use Sprint Quali data!\n",
    "\n",
    "**Blend strategy:**\n",
    "- 70% actual FP/Sprint Quali times (reality)\n",
    "- 30% model prediction (car-track fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "import warnings\n",
    "\n",
    "from src.predictors.blended_predictor import (\n",
    "    format_comparison,\n",
    "    predict_with_blending,\n",
    ")\n",
    "from src.predictors.driver_predictor import DriverRanker\n",
    "from src.predictors.team_predictor import rank_teams_for_track\n",
    "from src.utils.lineup_manager import get_lineups\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Season: 2025\n",
      "Demo race: Bahrain Grand Prix\n",
      "Blend: 70% FP data, 30% model\n"
     ]
    }
   ],
   "source": [
    "# Which season and race?\n",
    "SEASON = 2025\n",
    "DEMO_RACE = 'Bahrain Grand Prix'\n",
    "\n",
    "# Blending weight (70% FP data is recommended)\n",
    "FP_WEIGHT = 0.7\n",
    "\n",
    "print(f\"Season: {SEASON}\")\n",
    "print(f\"Demo race: {DEMO_RACE}\")\n",
    "print(f\"Blend: {FP_WEIGHT*100:.0f}% FP data, {(1-FP_WEIGHT)*100:.0f}% model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10185d26023b46108eb7d9f57d49d2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded characteristics for 27 drivers\n",
      "üü¢ Loaded: tracks (24), teams (10), driver ranker, results (24 races)\n"
     ]
    }
   ],
   "source": [
    "# Track what loaded\n",
    "loaded = []\n",
    "errors = []\n",
    "\n",
    "# Load track characteristics\n",
    "try:\n",
    "    track_path = Path(f'../data/processed/testing_files/track_characteristics/{SEASON}_track_characteristics.json')\n",
    "    with open(track_path) as f:\n",
    "        track_data = json.load(f)\n",
    "    all_tracks = track_data.get('tracks', {})\n",
    "    loaded.append(f\"tracks ({len(all_tracks)})\")\n",
    "except FileNotFoundError:\n",
    "    errors.append(\"track characteristics\")\n",
    "    all_tracks = {}\n",
    "\n",
    "# Load car characteristics\n",
    "try:\n",
    "    car_path = Path(f'../data/processed/testing_files/car_characteristics/{SEASON}_car_characteristics.json')\n",
    "    with open(car_path) as f:\n",
    "        car_data = json.load(f)\n",
    "    all_cars = car_data.get('teams', {})\n",
    "    loaded.append(f\"teams ({len(all_cars)})\")\n",
    "except FileNotFoundError:\n",
    "    errors.append(\"car characteristics\")\n",
    "    all_cars = {}\n",
    "\n",
    "# Load driver ranker\n",
    "try:\n",
    "    driver_ranker = DriverRanker(\n",
    "        '../data/processed/testing_files/driver_characteristics/driver_characteristics.json'\n",
    "    )\n",
    "    loaded.append(\"driver ranker\")\n",
    "except FileNotFoundError:\n",
    "    errors.append(\"driver characteristics\")\n",
    "    driver_ranker = None\n",
    "\n",
    "# Load actual results for validation (optional)\n",
    "try:\n",
    "    results_path = Path(f'../data/processed/testing_files/validation/{SEASON}_qualifying_results.json')\n",
    "    with open(results_path) as f:\n",
    "        actual_results = json.load(f)\n",
    "    loaded.append(f\"results ({actual_results.get('total_races', 0)} races)\")\n",
    "except FileNotFoundError:\n",
    "    actual_results = None\n",
    "\n",
    "# Print summary\n",
    "if loaded:\n",
    "    print(f\"üü¢ Loaded: {', '.join(loaded)}\")\n",
    "if errors:\n",
    "    print(f\"üî¥  Missing: {', '.join(errors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8763a12b2bbd4a93a75aff182afb95dc",
   "metadata": {},
   "source": [
    "## Demo: Single Race Blended Prediction\n",
    "\n",
    "Compare:\n",
    "1. Model-only prediction (what notebook 14 does)\n",
    "2. Blended prediction (model + FP data)\n",
    "3. Actual results\n",
    "\n",
    "**Expected:** Blended should be much better than model-only!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7623eae2785240b9bd12b16a66d81610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BLENDED PREDICTION: Bahrain Grand Prix (normal weekend)\n",
      "======================================================================\n",
      "\n",
      "STEP 1: Model Prediction\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Rank   Team                      Score     \n",
      "1      Mercedes                  0.399\n",
      "2      Red Bull Racing           0.383\n",
      "3      McLaren                   0.341\n",
      "4      Ferrari                   0.317\n",
      "5      Racing Bulls              0.292\n",
      "6      Williams                  0.290\n",
      "7      Aston Martin              0.210\n",
      "8      Alpine                    0.209\n",
      "9      Kick Sauber               0.193\n",
      "10     Haas F1 Team              0.062\n",
      "\n",
      "STEP 2: Extract FP Data\n",
      "----------------------------------------------------------------------\n",
      "Session used: FP3\n",
      "Blend type: fp_blended\n",
      "\n",
      "FP Performance:\n",
      "  McLaren                   1.000\n",
      "  Ferrari                   0.686\n",
      "  Mercedes                  0.657\n",
      "  Alpine                    0.545\n",
      "  Racing Bulls              0.532\n",
      "\n",
      "STEP 3: Comparison\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "PREDICTION COMPARISON\n",
      "======================================================================\n",
      "Team                      Model    Blended  Actual   Œî Model  Œî Blend \n",
      "----------------------------------------------------------------------\n",
      "McLaren                   3        1        1        2        0       \n",
      "Mercedes                  1        2        2        1        0       \n",
      "Ferrari                   4        3        3        1        0       \n",
      "Racing Bulls              5        4        12       7        8       \n",
      "Alpine                    8        5        5        3        0       \n",
      "Williams                  6        6        8        2        2       \n",
      "Red Bull Racing           2        7        7        5        0       \n",
      "Aston Martin              7        8        13       6        5       \n",
      "Haas F1 Team              10       9        14       4        5       \n",
      "Kick Sauber               9        10       16       7        6       \n",
      "\n",
      "ACCURACY (Team Level):\n",
      "----------------------------------------------------------------------\n",
      "  Model-only MAE:  3.80 positions\n",
      "  Blended MAE:     2.60 positions\n",
      "  Improvement:     +1.20 positions\n"
     ]
    }
   ],
   "source": [
    "if DEMO_RACE in all_tracks:\n",
    "    track = all_tracks[DEMO_RACE]\n",
    "    \n",
    "    # Determine weekend type\n",
    "    if actual_results and DEMO_RACE in actual_results['races']:\n",
    "        weekend_type = actual_results['races'][DEMO_RACE]['weekend_type']\n",
    "    else:\n",
    "        weekend_type = 'normal'  # Default\n",
    "    \n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"BLENDED PREDICTION: {DEMO_RACE} ({weekend_type} weekend)\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Step 1: Model prediction\n",
    "    print(\"\\nSTEP 1: Model Prediction\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    if weekend_type == 'sprint':\n",
    "        session = 'post_sprint_quali'\n",
    "    else:\n",
    "        session = 'post_fp3'\n",
    "    \n",
    "    team_rankings = rank_teams_for_track(all_cars, track, session, weekend_type)\n",
    "    model_ranks = {team: rank for rank, (team, _, _, _) in enumerate(team_rankings, 1)}\n",
    "    \n",
    "    print(f\"\\n{'Rank':<6} {'Team':<25} {'Score':<10}\")\n",
    "    for rank, (team, score, _, _) in enumerate(team_rankings, 1):\n",
    "        print(f\"{rank:<6} {team:<25} {score:.3f}\")\n",
    "    \n",
    "    # Step 2: Get actual FP data\n",
    "    print(\"\\nSTEP 2: Extract FP Data\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    blend_result = predict_with_blending(\n",
    "        SEASON,\n",
    "        DEMO_RACE,\n",
    "        model_ranks,\n",
    "        weekend_type=weekend_type,\n",
    "        weight_fp=FP_WEIGHT\n",
    "    )\n",
    "    \n",
    "    print(f\"Session used: {blend_result['session_used']}\")\n",
    "    print(f\"Blend type: {blend_result['blend_type']}\")\n",
    "    \n",
    "    if blend_result['blend_type'] == 'fp_blended':\n",
    "        print(\"\\nFP Performance:\")\n",
    "        sorted_fp = sorted(\n",
    "            blend_result['fp_performance'].items(),\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True\n",
    "        )\n",
    "        for team, perf in sorted_fp[:5]:\n",
    "            print(f\"  {team:<25} {perf:.3f}\")\n",
    "    \n",
    "    # Step 3: Compare predictions\n",
    "    print(\"\\nSTEP 3: Comparison\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    if actual_results and DEMO_RACE in actual_results['races']:\n",
    "        # Get actual team ranks\n",
    "        actual = actual_results['races'][DEMO_RACE]\n",
    "        actual_team_ranks = {}\n",
    "        \n",
    "        for pos_data in actual['positions']:\n",
    "            team = pos_data['team']\n",
    "            if team not in actual_team_ranks:\n",
    "                actual_team_ranks[team] = pos_data['position']\n",
    "        \n",
    "        format_comparison(\n",
    "            model_ranks,\n",
    "            blend_result['blended_ranks'],\n",
    "            actual_team_ranks\n",
    "        )\n",
    "        \n",
    "        # Calculate MAE\n",
    "        model_errors = []\n",
    "        blend_errors = []\n",
    "        \n",
    "        for team in model_ranks:\n",
    "            if team in actual_team_ranks:\n",
    "                model_errors.append(abs(model_ranks[team] - actual_team_ranks[team]))\n",
    "                blend_errors.append(abs(blend_result['blended_ranks'][team] - actual_team_ranks[team]))\n",
    "        \n",
    "        if model_errors:\n",
    "            print(\"\\nACCURACY (Team Level):\")\n",
    "            print(\"-\"*70)\n",
    "            print(f\"  Model-only MAE:  {np.mean(model_errors):.2f} positions\")\n",
    "            print(f\"  Blended MAE:     {np.mean(blend_errors):.2f} positions\")\n",
    "            print(f\"  Improvement:     {np.mean(model_errors) - np.mean(blend_errors):+.2f} positions\")\n",
    "    else:\n",
    "        format_comparison(\n",
    "            model_ranks,\n",
    "            blend_result['blended_ranks']\n",
    "        )\n",
    "    \n",
    "else:\n",
    "    print(f\"Race '{DEMO_RACE}' not found in track data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdc8c89c7104fffa095e18ddfef8986",
   "metadata": {},
   "source": [
    "## Full Grid with Blended Predictions\n",
    "\n",
    "Now convert blended team ranks to driver positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b118ea5561624da68c537baed56e602f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FULL GRID PREDICTION (Blended)\n",
      "======================================================================\n",
      "\n",
      "=== DRIVER POSITION PREDICTIONS (QUALIFYING) ===\n",
      "\n",
      "Total drivers: 20\n",
      "\n",
      "Pos  Driver  Team                    Confidence         Tier         Pace\n",
      "--------------------------------------------------------------------------------\n",
      " 1.  PIA     McLaren                1.0 [-3.0-5.0]    established   0.4908\n",
      " 2.  NOR     McLaren                2.0 [-2.0-6.0]    established   0.5090\n",
      " 3.  ANT     Mercedes               3.0 [-1.5-7.5]    developing    0.4641\n",
      " 4.  RUS     Mercedes               4.0 [0.5-7.5]     veteran       0.5565\n",
      " 5.  HAM     Ferrari                5.0 [0.5-9.5]     developing    0.4407\n",
      " 6.  LEC     Ferrari                6.0 [2.0-10.0]    established   0.5180\n",
      " 7.  LAW     Racing Bulls           7.0 [3.0-11.0]    established   0.4762\n",
      " 8.  HAD     Racing Bulls           8.0 [4.0-12.0]    established   0.5179\n",
      " 9.  DOO     Alpine                 9.0 [4.5-13.5]    developing    0.4675\n",
      "10.  GAS     Alpine                10.0 [6.0-14.0]    established   0.5108\n",
      "11.  SAI     Williams              11.5 [7.5-15.5]    established   0.5043\n",
      "12.  ALB     Williams              11.5 [7.5-15.5]    established   0.5047\n",
      "13.  TSU     Red Bull Racing       13.0 [8.5-17.5]    developing    0.4733\n",
      "14.  VER     Red Bull Racing       14.0 [10.5-17.5]   veteran       0.5683\n",
      "15.  STR     Aston Martin          15.1 [11.1-19.1]   established   0.4896\n",
      "16.  ALO     Aston Martin          15.9 [11.9-19.9]   established   0.5061\n",
      "17.  OCO     Haas F1 Team          17.3 [13.3-21.3]   established   0.4992\n",
      "18.  BEA     Haas F1 Team          17.7 [13.7-21.7]   established   0.5066\n",
      "19.  BOR     Kick Sauber           19.0 [15.0-23.0]   established   0.4892\n",
      "20.  HUL     Kick Sauber           20.0 [16.0-24.0]   established   0.5134\n",
      "\n",
      "VALIDATION\n",
      "----------------------------------------------------------------------\n",
      "  MAE:          3.48 positions\n",
      "  ¬±1 position:  15.0%\n",
      "  ¬±2 positions: 25.0%\n",
      "  ¬±3 positions: 45.0%\n"
     ]
    }
   ],
   "source": [
    "if blend_result['blend_type'] == 'fp_blended':\n",
    "    print(\"\\nFULL GRID PREDICTION (Blended)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Get lineups\n",
    "    lineups = get_lineups(SEASON, DEMO_RACE)\n",
    "    \n",
    "    # Predict driver positions using blended team ranks\n",
    "    driver_results = driver_ranker.predict_positions(\n",
    "        team_predictions=blend_result['blended_ranks'],\n",
    "        team_lineups=lineups,\n",
    "        session_type='qualifying'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{driver_ranker.format_predictions(driver_results, top_n=20)}\")\n",
    "    \n",
    "    # Validate if actual results available\n",
    "    if actual_results and DEMO_RACE in actual_results['races']:\n",
    "        actual = actual_results['races'][DEMO_RACE]\n",
    "        \n",
    "        print(\"\\nVALIDATION\")\n",
    "        print(\"-\"*70)\n",
    "        \n",
    "        errors = []\n",
    "        for pred in driver_results['predictions']:\n",
    "            actual_pos = next(\n",
    "                (p['position'] for p in actual['positions'] if p['driver'] == pred.driver),\n",
    "                None\n",
    "            )\n",
    "            if actual_pos:\n",
    "                errors.append(abs(pred.position - actual_pos))\n",
    "        \n",
    "        if errors:\n",
    "            mae = np.mean(errors)\n",
    "            within_1 = sum(1 for e in errors if e <= 1) / len(errors)\n",
    "            within_2 = sum(1 for e in errors if e <= 2) / len(errors)\n",
    "            within_3 = sum(1 for e in errors if e <= 3) / len(errors)\n",
    "            \n",
    "            print(f\"  MAE:          {mae:.2f} positions\")\n",
    "            print(f\"  ¬±1 position:  {within_1*100:.1f}%\")\n",
    "            print(f\"  ¬±2 positions: {within_2*100:.1f}%\")\n",
    "            print(f\"  ¬±3 positions: {within_3*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938c804e27f84196a10c8828c723f798",
   "metadata": {},
   "source": [
    "## Full Season Validation\n",
    "\n",
    "Compare model-only vs blended across all races."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "504fb2a444614c0babb325280ed9130a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FULL SEASON VALIDATION: Model vs Blended\n",
      "======================================================================\n",
      "üü¢ Australian Grand Prix          Model: 3.58  Blended: 3.20  Œî: +0.38\n",
      "üü¢ Chinese Grand Prix             Model: 3.02  Blended: 2.72  Œî: +0.30\n",
      "üü¢ Japanese Grand Prix            Model: 3.99  Blended: 3.41  Œî: +0.58\n",
      "üü¢ Bahrain Grand Prix             Model: 3.58  Blended: 3.48  Œî: +0.10\n",
      "üü¢ Saudi Arabian Grand Prix       Model: 3.14  Blended: 2.81  Œî: +0.34\n",
      "üü¢ Miami Grand Prix               Model: 4.02  Blended: 3.02  Œî: +1.00\n",
      "üü¢ Emilia Romagna Grand Prix      Model: 4.50  Blended: 4.00  Œî: +0.50\n",
      "üü¢ Monaco Grand Prix              Model: 4.59  Blended: 3.39  Œî: +1.20\n",
      "üü¢ Spanish Grand Prix             Model: 4.20  Blended: 3.05  Œî: +1.15\n",
      "üî¥ Canadian Grand Prix            Model: 3.65  Blended: 4.30  Œî: -0.65\n",
      "üü¢ Austrian Grand Prix            Model: 4.59  Blended: 4.19  Œî: +0.40\n",
      "üü¢ British Grand Prix             Model: 3.99  Blended: 3.16  Œî: +0.83\n",
      "üü¢ Belgian Grand Prix             Model: 5.75  Blended: 3.95  Œî: +1.80\n",
      "üü¢ Hungarian Grand Prix           Model: 5.30  Blended: 4.15  Œî: +1.15\n",
      "üü¢ Dutch Grand Prix               Model: 3.44  Blended: 3.40  Œî: +0.04\n",
      "üü¢ Italian Grand Prix             Model: 5.39  Blended: 3.19  Œî: +2.20\n",
      "üî¥ Azerbaijan Grand Prix          Model: 3.31  Blended: 4.25  Œî: -0.94\n",
      "üî¥ Singapore Grand Prix           Model: 3.39  Blended: 3.87  Œî: -0.48\n",
      "üü¢ United States Grand Prix       Model: 4.59  Blended: 4.09  Œî: +0.50\n",
      "üü¢ Mexico City Grand Prix         Model: 4.34  Blended: 3.24  Œî: +1.11\n",
      "üü¢ S√£o Paulo Grand Prix           Model: 5.47  Blended: 3.34  Œî: +2.13\n",
      "üî¥ Las Vegas Grand Prix           Model: 5.55  Blended: 5.87  Œî: -0.32\n",
      "üü¢ Qatar Grand Prix               Model: 4.29  Blended: 2.70  Œî: +1.60\n",
      "üü¢ Abu Dhabi Grand Prix           Model: 5.50  Blended: 4.79  Œî: +0.71\n",
      "\n",
      "======================================================================\n",
      "OVERALL COMPARISON\n",
      "======================================================================\n",
      "\n",
      "Across 24 races:\n",
      "  Model-only MAE:  4.30 positions\n",
      "  Blended MAE:     3.65 positions\n",
      "  Improvement:     +0.65 positions (+15.1%)\n",
      "\n",
      "Races improved: 20/24 (83.3%)\n",
      "\n",
      "Normal weekends (18 races):\n",
      "  Average improvement: +0.46 positions\n",
      "\n",
      "Sprint weekends (6 races):\n",
      "  Average improvement: +1.22 positions\n"
     ]
    }
   ],
   "source": [
    "if actual_results:\n",
    "    print(\"\\nFULL SEASON VALIDATION: Model vs Blended\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    model_only_results = []\n",
    "    blended_results = []\n",
    "    \n",
    "    for race_name, race_data in actual_results['races'].items():\n",
    "        if race_name not in all_tracks:\n",
    "            continue\n",
    "        \n",
    "        track = all_tracks[race_name]\n",
    "        weekend_type = race_data['weekend_type']\n",
    "        \n",
    "        # Model prediction\n",
    "        if weekend_type == 'sprint':\n",
    "            session = 'post_sprint_quali'\n",
    "        else:\n",
    "            session = 'post_fp3'\n",
    "        \n",
    "        team_rankings = rank_teams_for_track(all_cars, track, session, weekend_type)\n",
    "        if not team_rankings:\n",
    "            continue\n",
    "        \n",
    "        model_ranks = {team: rank for rank, (team, _, _, _) in enumerate(team_rankings, 1)}\n",
    "        \n",
    "        # Blended prediction\n",
    "        blend_result = predict_with_blending(\n",
    "            SEASON,\n",
    "            race_name,\n",
    "            model_ranks,\n",
    "            weekend_type=weekend_type,\n",
    "            weight_fp=FP_WEIGHT\n",
    "        )\n",
    "        \n",
    "        # Get lineups and predict drivers\n",
    "        lineups = get_lineups(SEASON, race_name)\n",
    "        \n",
    "        # Model-only driver predictions\n",
    "        model_drivers = driver_ranker.predict_positions(\n",
    "            team_predictions=model_ranks,\n",
    "            team_lineups=lineups,\n",
    "            session_type='qualifying'\n",
    "        )\n",
    "        \n",
    "        # Blended driver predictions\n",
    "        blend_drivers = driver_ranker.predict_positions(\n",
    "            team_predictions=blend_result['blended_ranks'],\n",
    "            team_lineups=lineups,\n",
    "            session_type='qualifying'\n",
    "        )\n",
    "        \n",
    "        # Calculate errors\n",
    "        model_errors = []\n",
    "        blend_errors = []\n",
    "        \n",
    "        for pred in model_drivers['predictions']:\n",
    "            actual_pos = next(\n",
    "                (p['position'] for p in race_data['positions'] if p['driver'] == pred.driver),\n",
    "                None\n",
    "            )\n",
    "            if actual_pos:\n",
    "                model_errors.append(abs(pred.position - actual_pos))\n",
    "        \n",
    "        for pred in blend_drivers['predictions']:\n",
    "            actual_pos = next(\n",
    "                (p['position'] for p in race_data['positions'] if p['driver'] == pred.driver),\n",
    "                None\n",
    "            )\n",
    "            if actual_pos:\n",
    "                blend_errors.append(abs(pred.position - actual_pos))\n",
    "        \n",
    "        if model_errors and blend_errors:\n",
    "            model_mae = np.mean(model_errors)\n",
    "            blend_mae = np.mean(blend_errors)\n",
    "            \n",
    "            improvement = model_mae - blend_mae\n",
    "            \n",
    "            model_only_results.append({\n",
    "                'race': race_name,\n",
    "                'mae': model_mae,\n",
    "                'weekend_type': weekend_type\n",
    "            })\n",
    "            \n",
    "            blended_results.append({\n",
    "                'race': race_name,\n",
    "                'mae': blend_mae,\n",
    "                'improvement': improvement,\n",
    "                'blend_type': blend_result['blend_type'],\n",
    "                'weekend_type': weekend_type\n",
    "            })\n",
    "            \n",
    "            status = \"üü¢\" if improvement > 0 else \"üî¥\"\n",
    "            print(f\"{status} {race_name:<30} Model: {model_mae:.2f}  Blended: {blend_mae:.2f}  Œî: {improvement:+.2f}\")\n",
    "    \n",
    "    # Overall summary\n",
    "    if model_only_results and blended_results:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"OVERALL COMPARISON\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        overall_model_mae = np.mean([r['mae'] for r in model_only_results])\n",
    "        overall_blend_mae = np.mean([r['mae'] for r in blended_results])\n",
    "        overall_improvement = overall_model_mae - overall_blend_mae\n",
    "        \n",
    "        print(f\"\\nAcross {len(blended_results)} races:\")\n",
    "        print(f\"  Model-only MAE:  {overall_model_mae:.2f} positions\")\n",
    "        print(f\"  Blended MAE:     {overall_blend_mae:.2f} positions\")\n",
    "        print(f\"  Improvement:     {overall_improvement:+.2f} positions ({overall_improvement/overall_model_mae*100:+.1f}%)\")\n",
    "        \n",
    "        # Check how many races improved\n",
    "        improved = sum(1 for r in blended_results if r['improvement'] > 0)\n",
    "        print(f\"\\nRaces improved: {improved}/{len(blended_results)} ({improved/len(blended_results)*100:.1f}%)\")\n",
    "        \n",
    "        # By weekend type\n",
    "        normal_blend = [r for r in blended_results if r['weekend_type'] == 'normal']\n",
    "        sprint_blend = [r for r in blended_results if r['weekend_type'] == 'sprint']\n",
    "        \n",
    "        if normal_blend:\n",
    "            print(f\"\\nNormal weekends ({len(normal_blend)} races):\")\n",
    "            print(f\"  Average improvement: {np.mean([r['improvement'] for r in normal_blend]):+.2f} positions\")\n",
    "        \n",
    "        if sprint_blend:\n",
    "            print(f\"\\nSprint weekends ({len(sprint_blend)} races):\")\n",
    "            print(f\"  Average improvement: {np.mean([r['improvement'] for r in sprint_blend]):+.2f} positions\")\n",
    "else:\n",
    "    print(\"No actual results available for validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bbdb311c014d738909a11f9e486628",
   "metadata": {},
   "source": [
    "## Analysis: When Does Blending Help Most?\n",
    "\n",
    "Check which tracks benefit most from FP data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b43b363d81ae4b689946ece5c682cd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRACKS WHERE BLENDING HELPS MOST\n",
      "======================================================================\n",
      "\n",
      "Track                          Improvement     Blend Type     \n",
      "----------------------------------------------------------------------\n",
      "Italian Grand Prix             +2.20 positions   fp_blended     \n",
      "S√£o Paulo Grand Prix           +2.13 positions   fp_blended     \n",
      "Belgian Grand Prix             +1.80 positions   fp_blended     \n",
      "Qatar Grand Prix               +1.60 positions   fp_blended     \n",
      "Monaco Grand Prix              +1.20 positions   fp_blended     \n",
      "Spanish Grand Prix             +1.15 positions   fp_blended     \n",
      "Hungarian Grand Prix           +1.15 positions   fp_blended     \n",
      "Mexico City Grand Prix         +1.11 positions   fp_blended     \n",
      "Miami Grand Prix               +1.00 positions   fp_blended     \n",
      "British Grand Prix             +0.83 positions   fp_blended     \n"
     ]
    }
   ],
   "source": [
    "if blended_results:\n",
    "    print(\"\\nTRACKS WHERE BLENDING HELPS MOST\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Sort by improvement\n",
    "    sorted_results = sorted(blended_results, key=lambda x: x['improvement'], reverse=True)\n",
    "    \n",
    "    print(f\"\\n{'Track':<30} {'Improvement':<15} {'Blend Type':<15}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    for result in sorted_results[:10]:\n",
    "        print(f\"{result['race']:<30} {result['improvement']:+.2f} positions   {result['blend_type']:<15}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
